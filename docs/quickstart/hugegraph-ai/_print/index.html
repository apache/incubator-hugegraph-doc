<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=content-security-policy content="script-src 'self' 'unsafe-inline'; script-src-elem 'self' 'unsafe-inline' https://code.jquery.com https://cdn.jsdelivr.net https://fonts.googleapis.com;"><meta name=generator content="Hugo 0.102.3"><link rel=canonical type=text/html href=/docs/quickstart/hugegraph-ai/><link rel=alternate type=application/rss+xml href=/docs/quickstart/hugegraph-ai/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>HugeGraph-AI | HugeGraph</title><meta name=description content="

üöÄ Best practice: Prioritize using DeepWiki intelligent documents

To address the issue of outdated static documents, we provide DeepWiki with ‚Ä¶"><meta property="og:title" content="HugeGraph-AI"><meta property="og:description" content="Apache HugeGraph site"><meta property="og:type" content="website"><meta property="og:url" content="/docs/quickstart/hugegraph-ai/"><meta property="og:site_name" content="HugeGraph"><meta itemprop=name content="HugeGraph-AI"><meta itemprop=description content="Apache HugeGraph site"><meta name=twitter:card content="summary"><meta name=twitter:title content="HugeGraph-AI"><meta name=twitter:description content="Apache HugeGraph site"><link rel=preload href=/scss/main.min.3276a99ddd5b15fbe3fcf20f8237086c2cbb526b572f4f06a2246fa9279ed395.css as=style><link href=/scss/main.min.3276a99ddd5b15fbe3fcf20f8237086c2cbb526b572f4f06a2246fa9279ed395.css rel=stylesheet integrity><script src=/js/jquery.min.js></script>
<link rel=stylesheet href=/css/prism.css><script>document.addEventListener("DOMContentLoaded",function(){var t=document.querySelectorAll("pre code.language-mermaid, code.language-mermaid, pre code.language-fallback, code.language-fallback"),e=[];t.forEach(function(t){var n=t.textContent.trim();(n.match(/^(graph|flowchart|sequenceDiagram|classDiagram|pie|gitgraph|erDiagram|journey|gantt|stateDiagram|mindmap|timeline|quadrantChart)/m)||n.includes("-->")||n.includes("->")||n.includes("style ")||n.includes("fill:"))&&e.push(t)}),e.length>0&&(e.forEach(function(e){var n,t=document.createElement("div");t.className="mermaid",t.textContent=e.textContent.trim(),n=e.closest("pre")||e.parentElement,n.parentNode.replaceChild(t,n)}),mermaid.initialize({startOnLoad:!0,theme:"default",securityLevel:"loose"}))})</script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class=navbar-logo><svg id="ÂõæÂ±Ç_1" data-name="ÂõæÂ±Ç 1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 16 16"><defs><style>.logo-cls-1{fill:none;stroke:#fff;stroke-miterlimit:10;stroke-width:.5px;opacity:.3}.logo-cls-2{fill:#229efa}.logo-cls-3{fill:#9948f7}.logo-cls-4{fill:#33bc7a}.logo-cls-5{fill:url(#Êú™ÂëΩÂêçÁöÑÊ∏êÂèò_3)}.logo-cls-6{fill:url(#Êú™ÂëΩÂêçÁöÑÊ∏êÂèò_13)}.logo-cls-7{fill:url(#Êú™ÂëΩÂêçÁöÑÊ∏êÂèò_11)}</style><linearGradient id="Êú™ÂëΩÂêçÁöÑÊ∏êÂèò_3" x1="6.16" y1="14.63" x2="6.16" y2="6.01" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#2e3192"/><stop offset="0" stop-color="#229efa"/><stop offset=".44" stop-color="#239cf8"/><stop offset=".6" stop-color="#2795f2"/><stop offset=".71" stop-color="#2d8ae8"/><stop offset=".81" stop-color="#3679d9"/><stop offset=".89" stop-color="#4263c6"/><stop offset=".95" stop-color="#5048af"/><stop offset="1" stop-color="#5c319b"/></linearGradient><linearGradient id="Êú™ÂëΩÂêçÁöÑÊ∏êÂèò_13" x1="10.75" y1="8.2" x2="4.49" y2="1.94" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#991146"/><stop offset="0" stop-color="#326b4e"/><stop offset=".02" stop-color="#3a685c"/><stop offset=".07" stop-color="#506180"/><stop offset=".13" stop-color="#645aa0"/><stop offset=".19" stop-color="#7554bc"/><stop offset=".26" stop-color="#8250d2"/><stop offset=".35" stop-color="#8d4ce3"/><stop offset=".45" stop-color="#944aee"/><stop offset=".6" stop-color="#9848f5"/><stop offset="1" stop-color="#9948f7"/></linearGradient><linearGradient id="Êú™ÂëΩÂêçÁöÑÊ∏êÂèò_11" x1="15.34" y1="6.67" x2="7.88" y2="10.98" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#33bc7a"/><stop offset=".45" stop-color="#32ba7a"/><stop offset=".61" stop-color="#2fb37c"/><stop offset=".73" stop-color="#29a87e"/><stop offset=".82" stop-color="#219782"/><stop offset=".9" stop-color="#168186"/><stop offset=".97" stop-color="#09668b"/><stop offset="1" stop-color="#03598e"/></linearGradient></defs><title>logo</title><rect class="logo-cls-1" x="-143.14" y="-373.46" width="597.8" height="424.44"/><circle class="logo-cls-2" cx="12.02" cy="1.83" r="1.33"/><circle class="logo-cls-3" cx="12.02" cy="14.17" r="1.33"/><circle class="logo-cls-4" cx="1.33" cy="8" r="1.33"/><path class="logo-cls-5" d="M7.91 10h0a2.65 2.65.0 01-.23-3.74A1.75 1.75.0 017.91 6h0A2.66 2.66.0 014.4 6h0a1.81 1.81.0 01.24.24A2.65 2.65.0 014.4 10h0a2.62 2.62.0 00-.89 2 2.65 2.65.0 104.4-2z"/><path class="logo-cls-6" d="M12.19 5.49a2.78 2.78.0 01-.5.11A2.64 2.64.0 018.76 3.5h0a2.65 2.65.0 10-2.6 3.17A2.6 2.6.0 007 6.53H7a2.65 2.65.0 013.44 2 2.94 2.94.0 010-.51 2.65 2.65.0 011.75-2.53z"/><path class="logo-cls-7" d="M13 5.35a2.64 2.64.0 00-2.59 2.12h0a3 3 0 01-.08.32A2.65 2.65.0 017.54 9.58a2.86 2.86.0 00.37.41h0a2.63 2.63.0 01.9 2 2.84 2.84.0 01-.05.51 2.64 2.64.0 013.12-2.06l.32.08h0a2.6 2.6.0 00.84.14 2.65 2.65.0 100-5.3z"/></svg></span><span class=font-weight-bold>HugeGraph</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/docs/><i class='fas fa-book pr-2'></i><span>Documentation</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/blog/><i class='fas fa-book pr-2'></i><span>Blog Posts</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://github.com/apache/incubator-hugegraph target=_blank><i class='fab fa-github pr-2'></i><span>GitHub</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/docs/download/download/><i class='fas fa-download pr-2'></i><span>Download</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/community/><span>Community</span></a></li><li class="nav-item dropdown mr-4 d-none d-lg-block"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><div class=dropdown-menu aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/cn/docs/quickstart/hugegraph-ai/>‰∏≠Êñá</a></div></li></ul></div><div class="navbar-nav d-none d-lg-block"></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/quickstart/hugegraph-ai/>Return to the regular view of this page</a>.</p></div><h1 class=title>HugeGraph-AI</h1><ul><li>1: <a href=#pg-0b4da31f88e2852fb8a360769f3c9f28>HugeGraph-LLM</a></li><li>2: <a href=#pg-bb10fc095f5061d789104547f7246a67>GraphRAG UI Details</a></li></ul><div class=content><p><a href=https://www.apache.org/licenses/LICENSE-2.0.html><img src=https://img.shields.io/badge/license-Apache%202-0E78BA.svg alt=License></a>
<a href=https://deepwiki.com/apache/incubator-hugegraph-ai><img src=https://deepwiki.com/badge.svg alt="Ask DeepWiki"></a></p><h2 id=-best-practice-prioritize-using-deepwiki-intelligent-documents>üöÄ Best practice: Prioritize using DeepWiki intelligent documents</h2><blockquote><p>To address the issue of outdated static documents, we provide DeepWiki with <strong>real-time updates and more comprehensive content</strong>. It is equivalent to an expert with the latest knowledge of the project, which is very suitable for <strong>all developers</strong> to read and consult before starting the project.</p></blockquote><p><strong>üëâ Strongly recommend visiting and having a conversation with:</strong> <a href=https://deepwiki.com/apache/incubator-hugegraph-ai><strong>incubator-hugegraph-ai</strong></a></p><p><code>hugegraph-ai</code> integrates <a href=https://github.com/apache/hugegraph>HugeGraph</a> with artificial intelligence capabilities, providing comprehensive support for developers to build AI-powered graph applications.</p><h2 id=-key-features>‚ú® Key Features</h2><ul><li><strong>GraphRAG</strong>: Build intelligent question-answering systems with graph-enhanced retrieval</li><li><strong>Knowledge Graph Construction</strong>: Automated graph building from text using LLMs</li><li><strong>Graph ML</strong>: Integration with 20+ graph learning algorithms (GCN, GAT, GraphSAGE, etc.)</li><li><strong>Python Client</strong>: Easy-to-use Python interface for HugeGraph operations</li><li><strong>AI Agents</strong>: Intelligent graph analysis and reasoning capabilities</li></ul><h2 id=-quick-start>üöÄ Quick Start</h2><blockquote><p>[!NOTE]
For a complete deployment guide and detailed examples, please refer to <a href=https://github.com/apache/incubator-hugegraph-ai/blob/main/hugegraph-llm/README.md>hugegraph-llm/README.md</a></p></blockquote><h3 id=prerequisites>Prerequisites</h3><ul><li>Python 3.9+ (3.10+ recommended for hugegraph-llm)</li><li><a href=https://docs.astral.sh/uv/>uv</a> (recommended package manager)</li><li>HugeGraph Server 1.3+ (1.5+ recommended)</li><li>Docker (optional, for containerized deployment)</li></ul><h3 id=option-1-docker-deployment-recommended>Option 1: Docker Deployment (Recommended)</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Clone the repository</span>
</span></span><span style=display:flex><span>git clone https://github.com/apache/incubator-hugegraph-ai.git
</span></span><span style=display:flex><span><span style=color:#204a87>cd</span> incubator-hugegraph-ai
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Set up environment and start services</span>
</span></span><span style=display:flex><span>cp docker/env.template docker/.env
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Edit docker/.env to set your PROJECT_PATH</span>
</span></span><span style=display:flex><span><span style=color:#204a87>cd</span> docker
</span></span><span style=display:flex><span>docker-compose -f docker-compose-network.yml up -d
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Access services:</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># - HugeGraph Server: http://localhost:8080</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># - RAG Service: http://localhost:8001</span>
</span></span></code></pre></div><h3 id=option-2-source-installation>Option 2: Source Installation</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 1. Start HugeGraph Server</span>
</span></span><span style=display:flex><span>docker run -itd --name<span style=color:#ce5c00;font-weight:700>=</span>server -p 8080:8080 hugegraph/hugegraph
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 2. Clone and set up the project</span>
</span></span><span style=display:flex><span>git clone https://github.com/apache/incubator-hugegraph-ai.git
</span></span><span style=display:flex><span><span style=color:#204a87>cd</span> incubator-hugegraph-ai/hugegraph-llm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 3. Install dependencies</span>
</span></span><span style=display:flex><span>uv venv <span style=color:#ce5c00;font-weight:700>&amp;&amp;</span> <span style=color:#204a87>source</span> .venv/bin/activate
</span></span><span style=display:flex><span>uv pip install -e .
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 4. Start the demo</span>
</span></span><span style=display:flex><span>python -m hugegraph_llm.demo.rag_demo.app
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Visit http://127.0.0.1:8001</span>
</span></span></code></pre></div><h3 id=basic-usage-examples>Basic Usage Examples</h3><h4 id=graphrag---question-answering>GraphRAG - Question Answering</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>hugegraph_llm.operators.graph_rag_task</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>RAGPipeline</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Initialize RAG pipeline</span>
</span></span><span style=display:flex><span><span style=color:#000>graph_rag</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>RAGPipeline</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Ask questions about your graph</span>
</span></span><span style=display:flex><span><span style=color:#000>result</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000;font-weight:700>(</span><span style=color:#000>graph_rag</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>extract_keywords</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>text</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;Tell me about Al Pacino.&#34;</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>keywords_to_vid</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>query_graphdb</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>max_deep</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>2</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>max_graph_items</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>30</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>synthesize_answer</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>run</span><span style=color:#000;font-weight:700>())</span>
</span></span></code></pre></div><h4 id=knowledge-graph-construction>Knowledge Graph Construction</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>hugegraph_llm.models.llms.init_llm</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>LLMs</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>hugegraph_llm.operators.kg_construction_task</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>KgBuilder</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Build KG from text</span>
</span></span><span style=display:flex><span><span style=color:#000>TEXT</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#4e9a06>&#34;Your text content here...&#34;</span>
</span></span><span style=display:flex><span><span style=color:#000>builder</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>KgBuilder</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>LLMs</span><span style=color:#000;font-weight:700>()</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>get_chat_llm</span><span style=color:#000;font-weight:700>())</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>(</span><span style=color:#000>builder</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>import_schema</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>from_hugegraph</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;hugegraph&#34;</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>chunk_split</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>TEXT</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>extract_info</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>extract_type</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;property_graph&#34;</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>commit_to_hugegraph</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>run</span><span style=color:#000;font-weight:700>())</span>
</span></span></code></pre></div><h4 id=graph-machine-learning>Graph Machine Learning</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>pyhugegraph.client</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>PyHugeClient</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Connect to HugeGraph and run ML algorithms</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># See hugegraph-ml documentation for detailed examples</span>
</span></span></code></pre></div><h2 id=-modules>üì¶ Modules</h2><h3 id=hugegraph-llmhttpsgithubcomapacheincubator-hugegraph-aitreemainhugegraph-llm-ask-deepwikihttpsdeepwikicombadgesvghttpsdeepwikicomapacheincubator-hugegraph-ai><a href=https://github.com/apache/incubator-hugegraph-ai/tree/main/hugegraph-llm>hugegraph-llm</a> <a href=https://deepwiki.com/apache/incubator-hugegraph-ai><img src=https://deepwiki.com/badge.svg alt="Ask DeepWiki"></a></h3><p>Large language model integration for graph applications:</p><ul><li><strong>GraphRAG</strong>: Retrieval-augmented generation with graph data</li><li><strong>Knowledge Graph Construction</strong>: Build KGs from text automatically</li><li><strong>Natural Language Interface</strong>: Query graphs using natural language</li><li><strong>AI Agents</strong>: Intelligent graph analysis and reasoning</li></ul><h3 id=hugegraph-mlhttpsgithubcomapacheincubator-hugegraph-aitreemainhugegraph-ml><a href=https://github.com/apache/incubator-hugegraph-ai/tree/main/hugegraph-ml>hugegraph-ml</a></h3><p>Graph machine learning with 20+ implemented algorithms:</p><ul><li><strong>Node Classification</strong>: GCN, GAT, GraphSAGE, APPNP, etc.</li><li><strong>Graph Classification</strong>: DiffPool, P-GNN, etc.</li><li><strong>Graph Embedding</strong>: DeepWalk, Node2Vec, GRACE, etc.</li><li><strong>Link Prediction</strong>: SEAL, GATNE, etc.</li></ul><h3 id=hugegraph-python-clienthttpsgithubcomapacheincubator-hugegraph-aitreemainhugegraph-python-client><a href=https://github.com/apache/incubator-hugegraph-ai/tree/main/hugegraph-python-client>hugegraph-python-client</a></h3><p>Python client for HugeGraph operations:</p><ul><li><strong>Schema Management</strong>: Define vertex/edge labels and properties</li><li><strong>CRUD Operations</strong>: Create, read, update, delete graph data</li><li><strong>Gremlin Queries</strong>: Execute graph traversal queries</li><li><strong>REST API</strong>: Complete HugeGraph REST API coverage</li></ul><h2 id=-learn-more>üìö Learn More</h2><ul><li><a href=https://hugegraph.apache.org/docs/quickstart/hugegraph-ai/>Project Homepage</a></li><li><a href=https://github.com/apache/incubator-hugegraph-ai/blob/main/hugegraph-llm/quick_start.md>LLM Quick Start Guide</a></li><li><a href=https://deepwiki.com/apache/incubator-hugegraph-ai>DeepWiki AI Documentation</a></li></ul><h2 id=-related-projects>üîó Related Projects</h2><ul><li><a href=https://github.com/apache/hugegraph>hugegraph</a> - Core graph database</li><li><a href=https://github.com/apache/hugegraph-toolchain>hugegraph-toolchain</a> - Development tools (Loader, Dashboard, etc.)</li><li><a href=https://github.com/apache/hugegraph-computer>hugegraph-computer</a> - Graph computing system</li></ul><h2 id=-contributing>ü§ù Contributing</h2><p>We welcome contributions! Please see our <a href=https://hugegraph.apache.org/docs/contribution-guidelines/>contribution guidelines</a> for details.</p><p><strong>Development Setup:</strong></p><ul><li>Use <a href=https://desktop.github.com/>GitHub Desktop</a> for easier PR management</li><li>Run <code>./style/code_format_and_analysis.sh</code> before submitting PRs</li><li>Check existing issues before reporting bugs</li></ul><p><a href=https://github.com/apache/incubator-hugegraph-ai/graphs/contributors><img src="https://contrib.rocks/image?repo=apache/incubator-hugegraph-ai" alt="contributors graph"></a></p><h2 id=-license>üìÑ License</h2><p>hugegraph-ai is licensed under <a href=https://github.com/apache/incubator-hugegraph-ai/blob/main/LICENSE>Apache 2.0 License</a>.</p><h2 id=-contact-us>üìû Contact Us</h2><ul><li><strong>GitHub Issues</strong>: <a href=https://github.com/apache/incubator-hugegraph-ai/issues>Report bugs or request features</a> (fastest response)</li><li><strong>Email</strong>: <a href=mailto:dev@hugegraph.apache.org>dev@hugegraph.apache.org</a> (<a href=https://hugegraph.apache.org/docs/contribution-guidelines/subscribe/>subscription required</a>)</li><li><strong>WeChat</strong>: Follow &ldquo;Apache HugeGraph&rdquo; on WeChat</li></ul><img src=https://raw.githubusercontent.com/apache/hugegraph-doc/master/assets/images/wechat.png alt="Apache HugeGraph WeChat QR Code" width=200></div></div><div class=td-content style=page-break-before:always><h1 id=pg-0b4da31f88e2852fb8a360769f3c9f28>1 - HugeGraph-LLM</h1><blockquote><p>Please refer to the AI repository <a href=https://github.com/apache/incubator-hugegraph-ai/tree/main/hugegraph-llm#readme>README</a> for the most up-to-date documentation, and the official website <strong>regularly</strong> is updated and synchronized.</p></blockquote><blockquote><p><strong>Bridge the gap between Graph Databases and Large Language Models</strong></p></blockquote><blockquote><p>AI summarizes the project documentation: <a href=https://deepwiki.com/apache/incubator-hugegraph-ai><img src=https://deepwiki.com/badge.svg alt="Ask DeepWiki"></a></p></blockquote><h2 id=-overview>üéØ Overview</h2><p>HugeGraph-LLM is a comprehensive toolkit that combines the power of graph databases with large language models.
It enables seamless integration between HugeGraph and LLMs for building intelligent applications.</p><h3 id=key-features>Key Features</h3><ul><li>üèóÔ∏è <strong>Knowledge Graph Construction</strong> - Build KGs automatically using LLMs + HugeGraph</li><li>üó£Ô∏è <strong>Natural Language Querying</strong> - Operate graph databases using natural language (Gremlin/Cypher)</li><li>üîç <strong>Graph-Enhanced RAG</strong> - Leverage knowledge graphs to improve answer accuracy (GraphRAG & Graph Agent)</li></ul><p>For detailed source code doc, visit our <a href=https://deepwiki.com/apache/incubator-hugegraph-ai>DeepWiki</a> page. (Recommended)</p><h2 id=-prerequisites>üìã Prerequisites</h2><blockquote><p>[!IMPORTANT]</p><ul><li><strong>Python</strong>: 3.10+ (not tested on 3.12)</li><li><strong>HugeGraph Server</strong>: 1.3+ (recommended: 1.5+)</li><li><strong>UV Package Manager</strong>: 0.7+</li></ul></blockquote><h2 id=-quick-start>üöÄ Quick Start</h2><p>Choose your preferred deployment method:</p><h3 id=option-1-docker-compose-recommended>Option 1: Docker Compose (Recommended)</h3><p>The fastest way to get started with both HugeGraph Server and RAG Service:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 1. Set up environment</span>
</span></span><span style=display:flex><span>cp docker/env.template docker/.env
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Edit docker/.env and set PROJECT_PATH to your actual project path</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 2. Deploy services</span>
</span></span><span style=display:flex><span><span style=color:#204a87>cd</span> docker
</span></span><span style=display:flex><span>docker-compose -f docker-compose-network.yml up -d
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 3. Verify deployment</span>
</span></span><span style=display:flex><span>docker-compose -f docker-compose-network.yml ps
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 4. Access services</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># HugeGraph Server: http://localhost:8080</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># RAG Service: http://localhost:8001</span>
</span></span></code></pre></div><h3 id=option-2-individual-docker-containers>Option 2: Individual Docker Containers</h3><p>For more control over individual components:</p><h4 id=available-images>Available Images</h4><ul><li><strong><code>hugegraph/rag</code></strong> - Development image with source code access</li><li><strong><code>hugegraph/rag-bin</code></strong> - Production-optimized binary (compiled with Nuitka)</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 1. Create network</span>
</span></span><span style=display:flex><span>docker network create -d bridge hugegraph-net
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 2. Start HugeGraph Server</span>
</span></span><span style=display:flex><span>docker run -itd --name<span style=color:#ce5c00;font-weight:700>=</span>server -p 8080:8080 --network hugegraph-net hugegraph/hugegraph
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 3. Start RAG Service</span>
</span></span><span style=display:flex><span>docker pull hugegraph/rag:latest
</span></span><span style=display:flex><span>docker run -itd --name rag <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  -v /path/to/your/hugegraph-llm/.env:/home/work/hugegraph-llm/.env <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  -p 8001:8001 --network hugegraph-net hugegraph/rag
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 4. Monitor logs</span>
</span></span><span style=display:flex><span>docker logs -f rag
</span></span></code></pre></div><h3 id=option-3-build-from-source>Option 3: Build from Source</h3><p>For development and customization:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 1. Start HugeGraph Server</span>
</span></span><span style=display:flex><span>docker run -itd --name<span style=color:#ce5c00;font-weight:700>=</span>server -p 8080:8080 hugegraph/hugegraph
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 2. Install UV package manager</span>
</span></span><span style=display:flex><span>curl -LsSf https://astral.sh/uv/install.sh <span style=color:#000;font-weight:700>|</span> sh
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 3. Clone and setup project</span>
</span></span><span style=display:flex><span>git clone https://github.com/apache/incubator-hugegraph-ai.git
</span></span><span style=display:flex><span><span style=color:#204a87>cd</span> incubator-hugegraph-ai/hugegraph-llm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 4. Create virtual environment and install dependencies</span>
</span></span><span style=display:flex><span>uv venv <span style=color:#ce5c00;font-weight:700>&amp;&amp;</span> <span style=color:#204a87>source</span> .venv/bin/activate
</span></span><span style=display:flex><span>uv pip install -e .
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 5. Launch RAG demo</span>
</span></span><span style=display:flex><span>python -m hugegraph_llm.demo.rag_demo.app
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Access at: http://127.0.0.1:8001</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># 6. (Optional) Custom host/port</span>
</span></span><span style=display:flex><span>python -m hugegraph_llm.demo.rag_demo.app --host 127.0.0.1 --port <span style=color:#0000cf;font-weight:700>18001</span>
</span></span></code></pre></div><h4 id=additional-setup-optional>Additional Setup (Optional)</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Download NLTK stopwords for better text processing</span>
</span></span><span style=display:flex><span>python ./hugegraph_llm/operators/common_op/nltk_helper.py
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Update configuration files</span>
</span></span><span style=display:flex><span>python -m hugegraph_llm.config.generate --update
</span></span></code></pre></div><blockquote><p>[!TIP]
Check our <a href=https://github.com/apache/incubator-hugegraph-ai/blob/main/hugegraph-llm/quick_start.md>Quick Start Guide</a> for detailed usage examples and query logic explanations.</p></blockquote><h2 id=-usage-examples>üí° Usage Examples</h2><h3 id=knowledge-graph-construction>Knowledge Graph Construction</h3><h4 id=interactive-web-interface>Interactive Web Interface</h4><p>Use the Gradio interface for visual knowledge graph building:</p><p><strong>Input Options:</strong></p><ul><li><strong>Text</strong>: Direct text input for RAG index creation</li><li><strong>Files</strong>: Upload TXT or DOCX files (multiple selection supported)</li></ul><p><strong>Schema Configuration:</strong></p><ul><li><strong>Custom Schema</strong>: JSON format following our <a href=https://github.com/apache/incubator-hugegraph-ai/blob/aff3bbe25fa91c3414947a196131be812c20ef11/hugegraph-llm/src/hugegraph_llm/config/config_data.py#L125>template</a></li><li><strong>HugeGraph Schema</strong>: Use existing graph instance schema (e.g., &ldquo;hugegraph&rdquo;)</li></ul><p><img src=https://hugegraph.apache.org/docs/images/gradio-kg.png alt="Knowledge Graph Builder"></p><h4 id=programmatic-construction>Programmatic Construction</h4><p>Build knowledge graphs with code using the <code>KgBuilder</code> class:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>hugegraph_llm.models.llms.init_llm</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>LLMs</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>hugegraph_llm.operators.kg_construction_task</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>KgBuilder</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Initialize and chain operations</span>
</span></span><span style=display:flex><span><span style=color:#000>TEXT</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#4e9a06>&#34;Your input text here...&#34;</span>
</span></span><span style=display:flex><span><span style=color:#000>builder</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>KgBuilder</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>LLMs</span><span style=color:#000;font-weight:700>()</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>get_chat_llm</span><span style=color:#000;font-weight:700>())</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>(</span>
</span></span><span style=display:flex><span>    <span style=color:#000>builder</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>import_schema</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>from_hugegraph</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;talent_graph&#34;</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>chunk_split</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>TEXT</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>extract_info</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>extract_type</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;property_graph&#34;</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>commit_to_hugegraph</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>run</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>)</span>
</span></span></code></pre></div><p><strong>Pipeline Workflow:</strong></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>graph LR
</span></span><span style=display:flex><span>    A[Import Schema] --&gt; B[Chunk Split]
</span></span><span style=display:flex><span>    B --&gt; C[Extract Info]
</span></span><span style=display:flex><span>    C --&gt; D[Commit to HugeGraph]
</span></span><span style=display:flex><span>    D --&gt; E[Execute Pipeline]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    style A fill:#fff2cc
</span></span><span style=display:flex><span>    style B fill:#d5e8d4
</span></span><span style=display:flex><span>    style C fill:#dae8fc
</span></span><span style=display:flex><span>    style D fill:#f8cecc
</span></span><span style=display:flex><span>    style E fill:#e1d5e7
</span></span></code></pre></div><h3 id=graph-enhanced-rag>Graph-Enhanced RAG</h3><p>Leverage HugeGraph for retrieval-augmented generation:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>hugegraph_llm.operators.graph_rag_task</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>RAGPipeline</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Initialize RAG pipeline</span>
</span></span><span style=display:flex><span><span style=color:#000>graph_rag</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>RAGPipeline</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Execute RAG workflow</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>(</span>
</span></span><span style=display:flex><span>    <span style=color:#000>graph_rag</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>extract_keywords</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>text</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;Tell me about Al Pacino.&#34;</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>keywords_to_vid</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>query_graphdb</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>max_deep</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>2</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>max_graph_items</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>30</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>merge_dedup_rerank</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>synthesize_answer</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>vector_only_answer</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#204a87;font-weight:700>False</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>graph_only_answer</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#204a87;font-weight:700>True</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>run</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>verbose</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#204a87;font-weight:700>True</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>)</span>
</span></span></code></pre></div><p><strong>RAG Pipeline Flow:</strong></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>graph TD
</span></span><span style=display:flex><span>    A[User Query] --&gt; B[Extract Keywords]
</span></span><span style=display:flex><span>    B --&gt; C[Match Graph Nodes]
</span></span><span style=display:flex><span>    C --&gt; D[Retrieve Graph Context]
</span></span><span style=display:flex><span>    D --&gt; E[Rerank Results]
</span></span><span style=display:flex><span>    E --&gt; F[Generate Answer]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    style A fill:#e3f2fd
</span></span><span style=display:flex><span>    style B fill:#f3e5f5
</span></span><span style=display:flex><span>    style C fill:#e8f5e8
</span></span><span style=display:flex><span>    style D fill:#fff3e0
</span></span><span style=display:flex><span>    style E fill:#fce4ec
</span></span><span style=display:flex><span>    style F fill:#e0f2f1
</span></span></code></pre></div><h2 id=-configuration>üîß Configuration</h2><p>After running the demo, configuration files are automatically generated:</p><ul><li><strong>Environment</strong>: <code>hugegraph-llm/.env</code></li><li><strong>Prompts</strong>: <code>hugegraph-llm/src/hugegraph_llm/resources/demo/config_prompt.yaml</code></li></ul><blockquote><p>[!NOTE]
Configuration changes are automatically saved when using the web interface. For manual changes, simply refresh the page to load updates.</p></blockquote><p><strong>LLM Provider Support</strong>: This project uses <a href=https://docs.litellm.ai/docs/providers>LiteLLM</a> for multi-provider LLM support.</p><h2 id=-additional-resources>üìö Additional Resources</h2><ul><li><strong>Graph Visualization</strong>: Use <a href=https://hub.docker.com/r/hugegraph/hubble>HugeGraph Hubble</a> for data analysis and schema management</li><li><strong>API Documentation</strong>: Explore our REST API endpoints for integration</li><li><strong>Community</strong>: Join our discussions and contribute to the project</li></ul><hr><p><strong>License</strong>: Apache License 2.0 | <strong>Community</strong>: <a href=https://hugegraph.apache.org/>Apache HugeGraph</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-bb10fc095f5061d789104547f7246a67>2 - GraphRAG UI Details</h1><blockquote><p>Follow up <a href=../>main doc</a> to introduce the basic UI function & details, welcome to update and improve at any time, thanks</p></blockquote><h1 id=1-core-logic-of-the-project>1. Core Logic of the Project</h1><h2 id=build-rag-index-responsibilities>Build RAG Index Responsibilities:</h2><ul><li>Split and vectorize text</li><li>Extract text into a graph (construct a knowledge graph) and vectorize the vertices</li></ul><h2 id=graphrag--user-functions-responsibilities>(Graph)RAG & User Functions Responsibilities:</h2><ul><li>Retrieve relevant content from the constructed knowledge graph and vector database based on the query to supplement the prompt.</li></ul><h1 id=2-processing-flow-build-rag-index>2. (Processing Flow) Build RAG Index</h1><p>Construct a knowledge graph, chunk vector, and graph vid vector from the text.</p><p><img src=https://github.com/user-attachments/assets/f3366d46-2e31-4638-94c4-7214951ef77a alt=image></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>graph TD;
</span></span><span style=display:flex><span>    A[Raw Text] --&gt; B[Text Segmentation]
</span></span><span style=display:flex><span>    B --&gt; C[Vectorization]
</span></span><span style=display:flex><span>    C --&gt; D[Store in Vector Database]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    A --&gt; F[Text Segmentation]
</span></span><span style=display:flex><span>    F --&gt; G[LLM extracts graph based on schema \nand segmented text]
</span></span><span style=display:flex><span>    G --&gt; H[Store graph in Graph Database, \nautomatically vectorize vertices \nand store in Vector Database]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    I[Retrieve vertices from Graph Database] --&gt; J[Vectorize vertices and store in Vector Database \nNote: Incremental update]
</span></span></code></pre></div><h3 id=four-input-fields>Four Input Fields:</h3><ul><li><strong>Doc(s):</strong> Input text</li><li><strong>Schema:</strong> The schema of the graph, which can be provided as a JSON-formatted schema or as the graph name (if it exists in the database).</li><li><strong>Graph</strong> <strong>Extract Prompt Header:</strong> The header of the prompt</li><li><strong>Output</strong>: Display results</li></ul><h3 id=buttons>Buttons:</h3><ul><li><p><strong>Get RAG Info</strong></p><ul><li><p><strong>Get Vector Index Info:</strong> Retrieve vector index information</p></li><li><p><strong>Get</strong> <strong>Graph</strong> <strong>Index Info:</strong> Retrieve graph index information</p></li></ul></li><li><p><strong>Clear RAG Data</strong></p><ul><li><strong>Clear Chunks Vector Index:</strong> Clear chunk vector</li><li><strong>Clear Graph Vid Vector Index</strong>: Clear graph vid vector</li><li><strong>Clear Graph Data</strong>: Clear Graph Data</li></ul></li><li><p><strong>Import into</strong> <strong>Vector</strong>: Convert the text in Doc(s) into vectors (requires chunking the text first and then converting the chunks into vectors)</p></li><li><p><strong>Extract</strong> <strong>Graph</strong> <strong>Data (1):</strong> Extract graph data from Doc(s) based on the Schema, using the Graph Extract Prompt Header and chunked content as the prompt</p></li><li><p><strong>Load into GraphDB (2):</strong> Store the extracted graph data into the database (automatically calls Update Vid Embedding to store vectors in the vector database)</p></li><li><p><strong>Update Vid Embedding:</strong> Convert graph vid into vectors</p></li></ul><h3 id=execution-flow>Execution Flow:</h3><ol><li>Input text into the <strong>Doc(s)</strong> field.</li><li>Click the <strong>Import into</strong> <strong>Vector</strong> button to split and vectorize the text, storing it in the vector database.</li><li>Input the graph <strong>Schema</strong> into the Schema field.</li><li>Click the <strong>Extract</strong> <strong>Graph</strong> <strong>Data (1)</strong> button to extract the text into a graph.</li><li>Click the <strong>Load into GraphDB (2)</strong> button to store the extracted graph into the graph database (this automatically calls <strong>Update Vid Embedding</strong> to store the vectors in the vector database).</li><li>Click the <strong>Update</strong> <strong>Vid</strong> <strong>Embedding</strong> button to vectorize the graph vertices and store them in the vector database.</li></ol><h1 id=3-processing-flow-graphrag--user-functions>3. (Processing Flow) (Graph)RAG & User Functions</h1><p>The <strong>Import into</strong> <strong>Vector</strong> button in the previous module converts text (chunks) into vectors, and the <strong>Update Vid Embedding</strong> button converts graph vid into vectors. These vectors are stored separately to supplement the context for queries (answer generation) in this module. In other words, the previous module prepares the data for RAG (vectorization), while this module executes RAG.</p><p>This module consists of two parts:</p><ul><li><strong>HugeGraph RAG</strong> <strong>Query</strong></li><li><strong>(Batch) Back-testing</strong></li></ul><p>The first part handles single queries, while the second part handles multiple queries at once. Below is an explanation of the first part.</p><p><img src=https://github.com/user-attachments/assets/33698062-e46b-4757-8b5e-93e8f10eae65 alt=image></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>graph TD;
</span></span><span style=display:flex><span>    A[Question] --&gt; B[Vectorize the question and search \nfor the most similar chunk in the Vector Database &amp;#40chunk&amp;#41]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    A --&gt; F[Extract keywords using LLM]
</span></span><span style=display:flex><span>    F --&gt; G[Match vertices precisely in Graph Database \nusing keywords; perform fuzzy matching in \nVector Database &amp;#40graph vid&amp;#41]
</span></span><span style=display:flex><span>    G --&gt; H[Generate Gremlin query using matched vertices and query with LLM]
</span></span><span style=display:flex><span>    H --&gt; I[Execute Gremlin query; if successful, finish; if failed, fallback to BFS]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    B --&gt; J[Sort results]
</span></span><span style=display:flex><span>    I --&gt; J
</span></span><span style=display:flex><span>    J --&gt; K[Generate answer]
</span></span></code></pre></div><h3 id=input-fields>Input Fields:</h3><ul><li><strong>Question:</strong> Input the query</li><li><strong>Query</strong> <strong>Prompt:</strong> The prompt template used to ask the final question to the LLM</li><li><strong>Keywords Extraction Prompt:</strong> The prompt template for extracting keywords from the question</li><li><strong>Template Num:</strong> &lt; 0 means disable text2gql; = 0 means no template(zero-shot); > 0 means using the specified number of templates</li></ul><h3 id=query-scope-selection>Query Scope Selection:</h3><ul><li><strong>Basic</strong> <strong>LLM</strong> <strong>Answer:</strong> Does not use RAG functionality</li><li><strong>Vector-only Answer:</strong> Uses only vector-based retrieval (queries chunk vectors in the vector database)</li><li><strong>Graph-only Answer:</strong> Uses only graph-based retrieval (queries graph vid vectors in the vector database and the graph database)</li><li><strong>Graph-Vector Answer:</strong> Uses both graph-based and vector-based retrieval</li></ul><p><img src=https://github.com/user-attachments/assets/26641e09-249f-4b3a-8013-16dc9383d333 alt=image></p><h3 id=execution-flow-1>Execution Flow:</h3><h4 id=graph-only-answer><strong>Graph-only Answer:</strong></h4><ul><li>Extract keywords from the <strong>question</strong> using the <strong>Keywords Extraction Prompt</strong>.</li></ul><p><img src=https://github.com/user-attachments/assets/b49e269f-eaec-40b1-8d8f-9e409821d75d alt=image></p><ul><li><p>Use the extracted keywords to:</p><ul><li><p>First, perform an exact match in the graph database.</p></li><li><p>If no match is found, perform a fuzzy match in the vector database (graph vid vector) to retrieve relevant vertices.</p></li></ul></li><li><p><strong>text2gql:</strong> Call the text2gql-related interface, using the matched vertices as entities to convert the <strong>question</strong> into a Gremlin query and execute it in the graph database.</p></li><li><p><strong>BFS:</strong> If text2gql fails (LLM-generated queries might be invalid), fall back to executing a graph query using a predefined <strong>Gremlin query template</strong> (essentially a BFS traversal).</p></li></ul><h4 id=vector-only-answer><strong>Vector-only Answer:</strong></h4><ul><li><p>Convert the <strong>query</strong> into a vector.</p></li><li><p>Search for the most similar content in the <strong>chunk vector</strong> dataset in the vector database.</p></li></ul><h4 id=sorting-and-answer-generation><strong>Sorting and Answer Generation:</strong></h4><ul><li><p>After executing the retrieval, sort the search (retrieval) results to construct the final <strong>prompt</strong>.</p></li><li><p>Generate answers based on different prompt configurations and display them in different output fields:</p><ul><li><strong>Basic</strong> <strong>LLM</strong> <strong>Answer</strong></li><li><strong>Vector-only Answer</strong></li><li><strong>Graph-only Answer</strong></li><li><strong>Graph-Vector Answer</strong></li></ul></li></ul><p><img src=https://github.com/user-attachments/assets/7d4496a3-d44c-4491-9463-8e93595dfa45 alt=image></p><h1 id=4-processing-flow-text2gremlin>4. (Processing Flow) Text2Gremlin</h1><p>Converts natural language queries into Gremlin queries.</p><p>This module consists of two parts:</p><ul><li><strong>Build</strong> <strong>Vector</strong> <strong>Template Index (Optional):</strong> Vectorizes query/gremlin pairs from sample files and stores them in the vector database for reference when generating Gremlin queries.</li><li><strong>Natural Language to Gremlin:</strong> Converts natural language queries into Gremlin queries.</li></ul><p>The first part is straightforward, so the focus is on the second part.</p><p><img src=https://github.com/user-attachments/assets/fc678369-261d-49ea-a289-1ca6ade5ca55 alt=image></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>graph TD;
</span></span><span style=display:flex><span>    A[Gremlin Pairs File] --&gt; C[Vectorize query]
</span></span><span style=display:flex><span>    C --&gt; D[Store in Vector Database]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    F[Natural Language Query] --&gt; G[Search for the most similar query \nin the Vector Database \n&amp;#40If no Gremlin pairs exist in the Vector Database, \ndefault files will be automatically vectorized&amp;#41 \nand retrieve the corresponding Gremlin]
</span></span><span style=display:flex><span>    G --&gt; H[Add the matched pair to the prompt \nand use LLM to generate the Gremlin \ncorresponding to the Natural Language Query]
</span></span></code></pre></div><h3 id=input-fields-for-the-second-part>Input Fields for the Second Part:</h3><ul><li><strong>Natural Language</strong> <strong>Query</strong>: Input the natural language text to be converted into Gremlin.</li></ul><p><img src=https://github.com/user-attachments/assets/d2a72f45-488c-4099-968b-a11816655ba0 alt=image></p><ul><li><strong>Schema:</strong> Input the graph schema.</li></ul><h3 id=execution-flow-2>Execution Flow:</h3><ol><li><p>Input the <strong>query</strong> (natural language) into the <strong>Natural Language Query</strong> field.</p></li><li><p>Input the <strong>graph</strong> <strong>schema</strong> into the <strong>Schema</strong> field.</p></li><li><p>Click the <strong>Text2Gremlin</strong> button, and the following execution logic applies:</p><ol><li><p>Convert the <strong>query</strong> into a vector.</p></li><li><p>Construct the <strong>prompt</strong>:</p><ul><li>Retrieve the <strong>graph schema</strong>.</li><li>Query the vector database for example vectors, retrieving query-gremlin pairs similar to the input query (if the vector database lacks examples, it automatically initializes with examples from the <strong>resources</strong> folder).</li></ul></li></ol></li></ol><p><img src=https://github.com/user-attachments/assets/fd150f87-27f8-48e5-8a55-319ec039b7e0 alt=image></p><pre><code>  - Generate the Gremlin query using the constructed prompt.
</code></pre><h1 id=5-graph-tools>5. Graph Tools</h1><p>Input Gremlin queries to execute corresponding operations.</p></div></main></div></div><footer class="bg-dark py-3 row d-print-none"><div class=footer-container><div class="row bg-dark"><div class=col-1></div><div class="col-4 text-center container-center"><div class=footer-row><a href=https://incubator.apache.org/><div class=footer-apache-logo><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 473.26 110.22"><defs><style>.cls-1,.cls-2{fill:#fff}.cls-1{fill-rule:evenodd}</style></defs><g id="Layer_2" data-name="Layer 2"><g id="Layer_1-2" data-name="Layer 1"><polygon class="cls-1" points="445.81 13.29 467.03 13.29 467.03 15.29 448.03 15.29 448.03 27.09 465.11 27.09 465.11 29.09 448.03 29.09 448.03 41.1 467.24 41.1 467.24 43.11 445.81 43.11 445.81 13.29"/><polygon class="cls-1" points="377.65 13.29 379.86 13.29 379.86 27.13 398.95 27.13 398.95 13.29 401.16 13.29 401.16 43.11 398.95 43.11 398.95 29.13 379.86 29.13 379.86 43.11 377.65 43.11 377.65 13.29"/><path class="cls-1" d="M323.93 43.62a14.55 14.55.0 01-10.63-4.45 14.92 14.92.0 01-3.09-4.88 16.21 16.21.0 01-1.11-6V28.2a15.89 15.89.0 014.24-10.89A14.42 14.42.0 01324 12.78a17.34 17.34.0 013.62.34 14 14 0 013 1 15.6 15.6.0 012.6 1.51 23.56 23.56.0 012.36 1.94L334 19.17a24 24 0 00-2-1.75A12.58 12.58.0 00329.7 16 13.11 13.11.0 00324 14.78a12.11 12.11.0 00-9 3.85 13.55 13.55.0 00-2.64 4.24 14.15 14.15.0 00-1 5.24v.09a14.1 14.1.0 001 5.26 13.67 13.67.0 002.67 4.26 12.2 12.2.0 004 2.85 11.83 11.83.0 005 1 12.39 12.39.0 005.63-1.2A17.89 17.89.0 00334.28 37l1.49 1.45a26.6 26.6.0 01-2.45 2.11 15 15 0 01-2.68 1.64 14.81 14.81.0 01-3.09 1.07A16.42 16.42.0 01323.93 43.62z"/><path class="cls-1" d="M252.32 13.07h2.13l13.89 30h-2.43l-3.79-8.35h-17.6l-3.79 8.35h-2.3l13.89-30zm8.86 19.69-7.84-17.26-7.88 17.26z"/><path class="cls-1" d="M176.74 13.29h10.82a15.11 15.11.0 014.5.62 10.36 10.36.0 013.49 1.78 8.21 8.21.0 012.28 2.86 8.78 8.78.0 01.81 3.85v.09a8.56 8.56.0 01-3.47 7.11 11.22 11.22.0 01-3.71 1.79A16.16 16.16.0 01187 32h-8V43.11h-2.22V13.29zM187.14 30a13.21 13.21.0 003.79-.51A8.65 8.65.0 00193.85 28a6.76 6.76.0 001.89-2.33 6.66 6.66.0 00.69-3v-.09a7 7 0 00-.67-3.15 6.12 6.12.0 00-1.85-2.25 8.68 8.68.0 00-2.85-1.37 13.6 13.6.0 00-3.67-.47H179V30z"/><path class="cls-1" d="M118.64 13.07h2.13l13.88 30h-2.42l-3.8-8.35H110.84l-3.79 8.35h-2.3l13.89-30zm8.86 19.69-7.84-17.26-7.88 17.26z"/><path class="cls-1" d="M471.26 70.85q0 10.83-9.44 13.64l11.44 15.88h-9.38L453.44 85.68h-9.7v14.69h-7.38V56.66h16.27q10 0 14.32 3.37t4.31 10.82zM452.94 79q6.26.0 8.5-1.93c1.5-1.3 2.25-3.37 2.25-6.23s-.77-4.81-2.31-5.88-4.29-1.59-8.25-1.59h-9.39V79z"/><path class="cls-1" d="M422.13 94.34a24 24 0 01-32.77.0 21.65 21.65.0 01-6.63-16.14 21.61 21.61.0 016.63-16.13 24 24 0 0132.77.0 21.61 21.61.0 016.63 16.13 21.65 21.65.0 01-6.63 16.14zM416.72 67a15.32 15.32.0 00-22 0 16.33 16.33.0 000 22.45 15.32 15.32.0 0022 0 16.33 16.33.0 000-22.45z"/><polygon class="cls-1" points="367.18 63.41 367.18 100.37 359.8 100.37 359.8 63.41 346.54 63.41 346.54 56.66 380.44 56.66 380.44 63.41 367.18 63.41"/><path class="cls-1" d="M315.61 90.43l-4.38 9.94h-7.88l19.27-43.71h7.88l19.26 43.71h-7.88l-4.38-9.94zm18.89-6.82-7.94-18-7.95 18z"/><path class="cls-1" d="M286.62 100.37H267.48V56.66h17a24.47 24.47.0 017.66 1.06 10.56 10.56.0 014.79 2.88 11.17 11.17.0 013 7.63c0 3.42-1.09 6-3.25 7.63A14.58 14.58.0 01295.06 77q-.44.22-1.56.72a11.54 11.54.0 016.5 3.61 10.23 10.23.0 012.41 6.91 11.76 11.76.0 01-3.13 8.07q-3.69 4.06-12.63 4.06zm-11.76-6.81h11.57a12.25 12.25.0 006.22-1.29c1.44-.85 2.16-2.47 2.16-4.84q0-5.82-9.32-5.82H274.86v12zm0-18.77h9.38q8 0 8-5.44a5.15 5.15.0 00-1.94-4.5c-1.29-.92-3.3-1.38-6-1.38h-9.44V74.79z"/><path class="cls-1" d="M231 90.37a11.19 11.19.0 0016.26.0q3-3.51 3-9.51V56.66h7.38V81.17q0 9.45-5.19 14.54a19.94 19.94.0 01-26.64.0q-5.19-5.08-5.19-14.54V56.66H228v24.2Q228 86.86 231 90.37z"/><path class="cls-1" d="M196.8 93.68a15.48 15.48.0 006.56-1.28 22.58 22.58.0 005.76-4.1l4.75 4.88A21.87 21.87.0 01197 100.87a22.57 22.57.0 01-16.45-6.38A21.58 21.58.0 01174 78.36a21.78 21.78.0 016.66-16.26q6.66-6.51 16.83-6.51a22 22 0 0117 7.51l-4.69 5.13A20.41 20.41.0 00203.9 64a16.46 16.46.0 00-6.54-1.19 15.54 15.54.0 00-11.13 4.28 14.48 14.48.0 00-4.51 11 15.12 15.12.0 004.48 11.13A14.48 14.48.0 00196.8 93.68z"/><polygon class="cls-1" points="159.05 56.66 166.43 56.66 166.43 100.37 158.42 100.37 133.66 68.48 133.66 100.37 126.28 100.37 126.28 56.66 133.66 56.66 159.05 89.3 159.05 56.66"/><rect class="cls-2" x="108.48" y="56.66" width="7.38" height="43.72"/><path class="cls-1" d="M44.92 15.1c0-.32.0-.64.0-1l.57 1zM33.16 49.33a49.36 49.36.0 00-5.89 20c-.44 6.17.22 11.49 2 16 .25.61.49 1.17.72 1.69q-2.13-1.52-4.07-3.15c-.11-.09-.19-.12-.24-.11a32.87 32.87.0 006.36 7.39c.39.34 1 .5 1.2 1 .46 1.45-.79 14.4 3.22 17.42 2.55 1.92 13.82-.49 17.3-1.62C71.92 102 86 85.26 83.9 61.11 81.61 34.62 64.16 7.68 46.75 1.2 42-.55 41-.39 36.11 1.7 19.13 9 2.45 35.25.21 61.11-1.95 86 13 103 31.9 108.36l1.48.41a19.49 19.49.0 01-1.2-3.36C12.38 99.52 1.31 82 3.1 61.36 4.81 41.65 18 12.6 37.25 4.37c4-1.72 4.41-2 8.48-.44C65.48 11.27 79.27 41.32 81 61.36 82.86 82.78 70.78 100.81 49.89 106a39.89 39.89.0 01-5.62 1c-5.42.55-7.3 1.5-8.29-4.13-2.19-12.44-.54-34.94 4.87-43.57a9.4 9.4.0 01-.4 1.5c-.18.44-.31.71-.36.85-3.24 7.42-5.05 28.95-3.5 33-.45-1.46.35-4.55 1.51-5.18l.66-.47c3.63-2.61 6-6.71 8.59-11.91.0-.07-.13-.07-.25.0a33.72 33.72.0 01-3.78 2.76A43.06 43.06.0 0051.06 68c-.06-.09-.16-.07-.31.0-.87.79-1.76 1.53-2.67 2.23 3.71-6.72 7-14.49 7.32-23.38a38.61 38.61.0 00-3.16-16.59c-.78-1.81-1.88-4-3.29-6.53C46.86 20 45.73 18 45.55 17.7c.1 8.15-1.34 14.78-4.31 19.84a60.7 60.7.0 01-4.09 5.86 46.12 46.12.0 00-3.99 5.93z"/></g></g></svg></div></a><ul class=footer-link><li><a class=white href=https://www.apache.org>Foundation</a></li><li><a class=white href=https://www.apache.org/licenses/>License</a></li><li><a class=white href=https://hugegraph.apache.org/docs/guides/security>Security</a></li><li><a class=white href=https://www.apache.org/events/current-event>Events</a></li><li><a class=white href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a></li><li><a class=white href=https://www.apache.org/foundation/thanks.html>Thanks</a></li><li><a class=white href=https://privacy.apache.org/policies/privacy-policy-public.html target=_blank>Privacy</a></li></ul></div></div><div class="col-6 text-white text-center container-center"><p>Apache HugeGraph is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.</p><p>Copyright &copy; 2026 The Apache Software Foundation, Licensed under the <a class=white href=https://www.apache.org/licenses/LICENSE-2.0>Apache License Version 2.0</a><br>Apache, the names of Apache projects, and the feather logo are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries.</p></div><div class=col-1></div></div></div></footer></div><script src=/js/popper.min.js></script>
<script src=/js/bootstrap.min.js></script>
<script src=/js/mermaid.min.js></script>
<script src=/js/tabpane-persist.js></script>
<script src=/js/main.min.e5172b35d915ae4e363d053ea36b47944d4363d50a61c129d222283019daf4e0.js integrity="sha256-5RcrNdkVrk42PQU+o2tHlE1DY9UKYcEp0iIoMBna9OA=" crossorigin=anonymous></script>
<script src=/js/prism.js></script></body></html>