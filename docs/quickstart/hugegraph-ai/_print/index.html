<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=content-security-policy content="script-src 'self'; script-src-elem 'self' https://code.jquery.com https://cdn.jsdelivr.net https://fonts.googleapis.com;"><meta name=generator content="Hugo 0.102.3"><link rel=canonical type=text/html href=/docs/quickstart/hugegraph-ai/><link rel=alternate type=application/rss+xml href=/docs/quickstart/hugegraph-ai/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>HugeGraph-AI | HugeGraph</title><meta name=description content="
Please refer to the AI repository README for the most up-to-date documentation, and the official website regularly is updated and synchronized.


AI ‚Ä¶"><meta property="og:title" content="HugeGraph-AI"><meta property="og:description" content="Apache HugeGraph site"><meta property="og:type" content="website"><meta property="og:url" content="/docs/quickstart/hugegraph-ai/"><meta property="og:site_name" content="HugeGraph"><meta itemprop=name content="HugeGraph-AI"><meta itemprop=description content="Apache HugeGraph site"><meta name=twitter:card content="summary"><meta name=twitter:title content="HugeGraph-AI"><meta name=twitter:description content="Apache HugeGraph site"><link rel=preload href=/scss/main.min.14ea575cb35d93d46ff8681b2334f40fd46243c100c5c39f5a841b931fae2d40.css as=style><link href=/scss/main.min.14ea575cb35d93d46ff8681b2334f40fd46243c100c5c39f5a841b931fae2d40.css rel=stylesheet integrity><script src=/js/jquery.min.js></script>
<link rel=stylesheet href=/css/prism.css></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class=navbar-logo><svg id="ÂõæÂ±Ç_1" data-name="ÂõæÂ±Ç 1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 16 16"><defs><style>.logo-cls-1{fill:none;stroke:#fff;stroke-miterlimit:10;stroke-width:.5px;opacity:.3}.logo-cls-2{fill:#229efa}.logo-cls-3{fill:#9948f7}.logo-cls-4{fill:#33bc7a}.logo-cls-5{fill:url(#Êú™ÂëΩÂêçÁöÑÊ∏êÂèò_3)}.logo-cls-6{fill:url(#Êú™ÂëΩÂêçÁöÑÊ∏êÂèò_13)}.logo-cls-7{fill:url(#Êú™ÂëΩÂêçÁöÑÊ∏êÂèò_11)}</style><linearGradient id="Êú™ÂëΩÂêçÁöÑÊ∏êÂèò_3" x1="6.16" y1="14.63" x2="6.16" y2="6.01" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#2e3192"/><stop offset="0" stop-color="#229efa"/><stop offset=".44" stop-color="#239cf8"/><stop offset=".6" stop-color="#2795f2"/><stop offset=".71" stop-color="#2d8ae8"/><stop offset=".81" stop-color="#3679d9"/><stop offset=".89" stop-color="#4263c6"/><stop offset=".95" stop-color="#5048af"/><stop offset="1" stop-color="#5c319b"/></linearGradient><linearGradient id="Êú™ÂëΩÂêçÁöÑÊ∏êÂèò_13" x1="10.75" y1="8.2" x2="4.49" y2="1.94" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#991146"/><stop offset="0" stop-color="#326b4e"/><stop offset=".02" stop-color="#3a685c"/><stop offset=".07" stop-color="#506180"/><stop offset=".13" stop-color="#645aa0"/><stop offset=".19" stop-color="#7554bc"/><stop offset=".26" stop-color="#8250d2"/><stop offset=".35" stop-color="#8d4ce3"/><stop offset=".45" stop-color="#944aee"/><stop offset=".6" stop-color="#9848f5"/><stop offset="1" stop-color="#9948f7"/></linearGradient><linearGradient id="Êú™ÂëΩÂêçÁöÑÊ∏êÂèò_11" x1="15.34" y1="6.67" x2="7.88" y2="10.98" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#33bc7a"/><stop offset=".45" stop-color="#32ba7a"/><stop offset=".61" stop-color="#2fb37c"/><stop offset=".73" stop-color="#29a87e"/><stop offset=".82" stop-color="#219782"/><stop offset=".9" stop-color="#168186"/><stop offset=".97" stop-color="#09668b"/><stop offset="1" stop-color="#03598e"/></linearGradient></defs><title>logo</title><rect class="logo-cls-1" x="-143.14" y="-373.46" width="597.8" height="424.44"/><circle class="logo-cls-2" cx="12.02" cy="1.83" r="1.33"/><circle class="logo-cls-3" cx="12.02" cy="14.17" r="1.33"/><circle class="logo-cls-4" cx="1.33" cy="8" r="1.33"/><path class="logo-cls-5" d="M7.91 10h0a2.65 2.65.0 01-.23-3.74A1.75 1.75.0 017.91 6h0A2.66 2.66.0 014.4 6h0a1.81 1.81.0 01.24.24A2.65 2.65.0 014.4 10h0a2.62 2.62.0 00-.89 2 2.65 2.65.0 104.4-2z"/><path class="logo-cls-6" d="M12.19 5.49a2.78 2.78.0 01-.5.11A2.64 2.64.0 018.76 3.5h0a2.65 2.65.0 10-2.6 3.17A2.6 2.6.0 007 6.53H7a2.65 2.65.0 013.44 2 2.94 2.94.0 010-.51 2.65 2.65.0 011.75-2.53z"/><path class="logo-cls-7" d="M13 5.35a2.64 2.64.0 00-2.59 2.12h0a3 3 0 01-.08.32A2.65 2.65.0 017.54 9.58a2.86 2.86.0 00.37.41h0a2.63 2.63.0 01.9 2 2.84 2.84.0 01-.05.51 2.64 2.64.0 013.12-2.06l.32.08h0a2.6 2.6.0 00.84.14 2.65 2.65.0 100-5.3z"/></svg></span><span class=font-weight-bold>HugeGraph</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/docs/><i class='fas fa-book pr-2'></i><span>Documentation</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://github.com/apache/incubator-hugegraph target=_blank><i class='fab fa-github pr-2'></i><span>GitHub</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/docs/download/download/><i class='fas fa-download pr-2'></i><span>Download</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/community/><span>Community</span></a></li><li class="nav-item dropdown mr-4 d-none d-lg-block"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><div class=dropdown-menu aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/cn/docs/quickstart/hugegraph-ai/>‰∏≠Êñá</a></div></li></ul></div><div class="navbar-nav d-none d-lg-block"></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/quickstart/hugegraph-ai/>Return to the regular view of this page</a>.</p></div><h1 class=title>HugeGraph-AI</h1><ul><li>1: <a href=#pg-bb10fc095f5061d789104547f7246a67>GraphRAG UI Details</a></li></ul><div class=content><blockquote><p>Please refer to the AI repository <a href=https://github.com/apache/incubator-hugegraph-ai/tree/main/hugegraph-llm#readme>README</a> for the most up-to-date documentation, and the official website <strong>regularly</strong> is updated and synchronized.</p></blockquote><blockquote><p>AI summarizes the project documentation: <a href=https://deepwiki.com/apache/incubator-hugegraph-ai><img src=https://deepwiki.com/badge.svg alt="Ask DeepWiki"></a></p></blockquote><h2 id=1-summary>1. Summary</h2><p>The <code>hugegraph-llm</code> is a tool for the implementation and research related to large language models.
This project includes runnable demos, it can also be used as a third-party library.</p><p>As we know, graph systems can help large models address challenges like timeliness and hallucination,
while large models can help graph systems with cost-related issues.</p><p>With this project, we aim to reduce the cost of using graph systems and decrease the complexity of
building knowledge graphs. This project will offer more applications and integration solutions for
graph systems and large language models.</p><ol><li>Construct knowledge graph by LLM + HugeGraph</li><li>Use natural language to operate graph databases (Gremlin/Cypher)</li><li>Knowledge graph supplements answer context (GraphRAG ‚Üí Graph Agent)</li></ol><h2 id=2-environment-requirements>2. Environment Requirements</h2><blockquote><p>[!IMPORTANT]</p><ul><li>python 3.10+ (not tested in 3.12)</li><li>hugegraph-server 1.3+ (better to use 1.5+)</li><li>uv 0.7+</li></ul></blockquote><h2 id=3-preparation>3. Preparation</h2><h3 id=31-docker>3.1 Docker</h3><p><strong>Docker Deployment</strong><br>Alternatively, you can deploy HugeGraph-AI using Docker:</p><ul><li>Ensure you have Docker installed</li><li>We provide two container images:<ul><li><strong>Image 1</strong>: <a href=https://hub.docker.com/r/hugegraph/rag/tags>hugegraph/rag</a><br>For building and running RAG functionality for rapid deployment and direct source code modification</li><li><strong>Image 2</strong>: <a href=https://hub.docker.com/r/hugegraph/rag-bin/tags>hugegraph/rag-bin</a><br>A binary translation of C compiled with Nuitka, for better performance and efficiency.</li></ul></li><li>Pull the Docker images:<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>docker pull hugegraph/rag:latest <span style=color:#8f5902;font-style:italic># Pull Image 1</span>
</span></span><span style=display:flex><span>docker pull hugegraph/rag-bin:latest <span style=color:#8f5902;font-style:italic># Pull Image 2</span>
</span></span></code></pre></div></li><li>Start the Docker container:<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>docker run -it --name rag -v path2project/hugegraph-llm/.env:/home/work/hugegraph-llm/.env -p 8001:8001 hugegraph/rag bash
</span></span><span style=display:flex><span>docker run -it --name rag-bin -v path2project/hugegraph-llm/.env:/home/work/hugegraph-llm/.env -p 8001:8001 hugegraph/rag-bin bash
</span></span></code></pre></div></li><li>Start the Graph RAG demo:<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># For Image 1</span>
</span></span><span style=display:flex><span>python ./src/hugegraph_llm/demo/rag_demo/app.py <span style=color:#8f5902;font-style:italic># or run python -m hugegraph_llm.demo.rag_demo.app</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># For Image 2</span>
</span></span><span style=display:flex><span>./app.dist/app.bin
</span></span></code></pre></div></li><li>Access the interface at http://localhost:8001</li></ul><h3 id=32-build-from-source>3.2 Build from Source</h3><ol><li><p>Start the HugeGraph database, you can run it via <a href=https://hub.docker.com/r/hugegraph/hugegraph>Docker</a>/<a href=https://hugegraph.apache.org/docs/download/download/>Binary Package</a>.
There is a simple method by docker:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>docker run -itd --name<span style=color:#ce5c00;font-weight:700>=</span>server -p 8080:8080 hugegraph/hugegraph
</span></span></code></pre></div><p>You can refer to the detailed documents <a href=/docs/quickstart/hugegraph/hugegraph-server/#31-use-docker-container-convenient-for-testdev>doc</a> for more guidance.</p></li><li><p>Configuring the uv environment, Use the official installer to install uv, See the <a href=https://docs.astral.sh/uv/configuration/installer/>uv documentation</a> for other installation methods</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># You could try pipx or pip to install uv when meet network issues, refer the uv doc for more details</span>
</span></span><span style=display:flex><span>curl -LsSf https://astral.sh/uv/install.sh <span style=color:#000;font-weight:700>|</span> sh  - <span style=color:#8f5902;font-style:italic># install the latest version like 0.7.3+</span>
</span></span></code></pre></div></li><li><p>Clone this project</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>git clone https://github.com/apache/incubator-hugegraph-ai.git
</span></span></code></pre></div></li><li><p>Configuration dependency environment</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#204a87>cd</span> incubator-hugegraph-ai/hugegraph-llm
</span></span><span style=display:flex><span>uv venv <span style=color:#ce5c00;font-weight:700>&amp;&amp;</span> <span style=color:#204a87>source</span> .venv/bin/activate
</span></span><span style=display:flex><span>uv pip install -e .
</span></span></code></pre></div><p>If dependency download fails or too slow due to network issues, it is recommended to modify <code>hugegraph-llm/pyproject.toml</code>.</p></li><li><p>To start the Gradio interactive demo for <strong>Graph RAG</strong>, run the following command, then open http://127.0.0.1:8001 in your browser.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python -m hugegraph_llm.demo.rag_demo.app  <span style=color:#8f5902;font-style:italic># same as &#34;uv run xxx&#34;</span>
</span></span></code></pre></div><p>The default host is <code>0.0.0.0</code> and the port is <code>8001</code>. You can change them by passing command line arguments<code>--host</code> and <code>--port</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python -m hugegraph_llm.demo.rag_demo.app --host 127.0.0.1 --port <span style=color:#0000cf;font-weight:700>18001</span>
</span></span></code></pre></div></li><li><p>After running the web demo, the config file <code>.env</code> will be automatically generated at the path <code>hugegraph-llm/.env</code>. Additionally, a prompt-related configuration file <code>config_prompt.yaml</code> will also be generated at the path <code>hugegraph-llm/src/hugegraph_llm/resources/demo/config_prompt.yaml</code>.
You can modify the content on the web page, and it will be automatically saved to the configuration file after the corresponding feature is triggered. You can also modify the file directly without restarting the web application; refresh the page to load your latest changes.<br>(Optional)To regenerate the config file, you can use <code>config.generate</code> with <code>-u</code> or <code>--update</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python -m hugegraph_llm.config.generate --update
</span></span></code></pre></div><p>Note: <code>Litellm</code> support multi-LLM provider, refer <a href=https://docs.litellm.ai/docs/providers>litellm.ai</a> to config it</p></li><li><p>(<strong>Optional</strong>) You could use
<a href=/docs/quickstart/toolchain/hugegraph-hubble/#21-use-docker-convenient-for-testdev>hugegraph-hubble</a>
to visit the graph data, could run it via <a href=https://hub.docker.com/r/hugegraph/hubble>Docker/Docker-Compose</a>
for guidance. (Hubble is a graph-analysis dashboard that includes data loading/schema management/graph traverser/display).</p></li><li><p>(<strong>Optional</strong>) offline download NLTK stopwords</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python ./hugegraph_llm/operators/common_op/nltk_helper.py
</span></span></code></pre></div></li></ol><blockquote><p>[!TIP]<br>You can also refer to our <a href=https://github.com/apache/incubator-hugegraph-ai/blob/main/hugegraph-llm/quick_start.md>quick-start</a> doc to understand how to use it & the basic query logic üöß</p></blockquote><h2 id=4-examples>4. Examples</h2><h3 id=41-build-a-knowledge-graph-in-hugegraph-through-llm>4.1 Build a knowledge graph in HugeGraph through LLM</h3><h4 id=411-build-a-knowledge-graph-through-the-gradio-interactive-interface>4.1.1 Build a knowledge graph through the gradio interactive interface</h4><p><strong>Parameter description:</strong></p><ul><li>Docs:<ul><li>text: Build rag index from plain text</li><li>file: Upload file(s) which should be <u>TXT</u> or <u>.docx</u> (Multiple files can be selected together)</li></ul></li><li><a href=https://hugegraph.apache.org/docs/clients/restful-api/schema/>Schema</a>: (Except <strong>2 types</strong>)<ul><li>User-defined Schema (JSON format, follow the <a href=https://github.com/apache/incubator-hugegraph-ai/blob/aff3bbe25fa91c3414947a196131be812c20ef11/hugegraph-llm/src/hugegraph_llm/config/config_data.py#L125>template</a>
to modify it)</li><li>Specify the name of the HugeGraph graph instance, it will automatically get the schema from it (like
<strong>&ldquo;hugegraph&rdquo;</strong>)</li></ul></li><li>Graph extract head: The user-defined prompt of graph extracting</li><li>If it already exists the graph data, you should click &ldquo;<strong>Rebuild vid Index</strong>&rdquo; to update the index</li></ul><p><img src=https://hugegraph.apache.org/docs/images/gradio-kg.png alt=gradio-config></p><h4 id=412-build-a-knowledge-graph-through-code>4.1.2 Build a knowledge graph through code</h4><p>The <code>KgBuilder</code> class is used to construct a knowledge graph. Here is a brief usage guide:</p><ol><li><p><strong>Initialization</strong>: The <code>KgBuilder</code> class is initialized with an instance of a language model.
This can be obtained from the <code>LLMs</code> class.<br>Initialize the LLMs instance, get the LLM, and then create a task instance <code>KgBuilder</code> for graph construction. <code>KgBuilder</code> defines multiple operators, and users can freely combine them according to their needs. (tip: <code>print_result()</code> can print the result of each step in the console, without affecting the overall execution logic)</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>hugegraph_llm.models.llms.init_llm</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>LLMs</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>hugegraph_llm.operators.kg_construction_task</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>KgBuilder</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000>TEXT</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#4e9a06>&#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#000>builder</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>KgBuilder</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>LLMs</span><span style=color:#000;font-weight:700>()</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>get_chat_llm</span><span style=color:#000;font-weight:700>())</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>(</span>
</span></span><span style=display:flex><span>    <span style=color:#000>builder</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>import_schema</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>from_hugegraph</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;talent_graph&#34;</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>chunk_split</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>TEXT</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>extract_info</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>extract_type</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;property_graph&#34;</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>commit_to_hugegraph</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>    <span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>run</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>)</span>
</span></span></code></pre></div><p><img src=https://hugegraph.apache.org/docs/images/kg-uml.png alt=gradio-config></p></li><li><p><strong>Import Schema</strong>: The <code>import_schema</code> method is used to import a schema from a source. The source can be a HugeGraph instance, a user-defined schema, or an extraction result. The method <code>print_result</code> can be chained to print the result.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Import schema from a HugeGraph instance</span>
</span></span><span style=display:flex><span><span style=color:#000>builder</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>import_schema</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>from_hugegraph</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;xxx&#34;</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Import schema from an extraction result</span>
</span></span><span style=display:flex><span><span style=color:#000>builder</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>import_schema</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>from_extraction</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;xxx&#34;</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Import schema from user-defined schema</span>
</span></span><span style=display:flex><span><span style=color:#000>builder</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>import_schema</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>from_user_defined</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;xxx&#34;</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span></code></pre></div></li><li><p><strong>Chunk Split</strong>: The <code>chunk_split</code> method is used to split the input text into chunks. The text should be passed as a string argument to the method.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Split the input text into documents</span>
</span></span><span style=display:flex><span><span style=color:#000>builder</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>chunk_split</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>TEXT</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>split_type</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;document&#34;</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Split the input text into paragraphs</span>
</span></span><span style=display:flex><span><span style=color:#000>builder</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>chunk_split</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>TEXT</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>split_type</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;paragraph&#34;</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Split the input text into sentences</span>
</span></span><span style=display:flex><span><span style=color:#000>builder</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>chunk_split</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>TEXT</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>split_type</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;sentence&#34;</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span></code></pre></div></li><li><p><strong>Extract Info</strong>: The <code>extract_info</code> method is used to extract info from a text. The text should be passed as a string argument to the method.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000>TEXT</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#4e9a06>&#34;Meet Sarah, a 30-year-old attorney, and her roommate, James, whom she&#39;s shared a home with since 2010.&#34;</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># extract property graph from the input text</span>
</span></span><span style=display:flex><span><span style=color:#000>builder</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>extract_info</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>extract_type</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;property_graph&#34;</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># extract triples from the input text</span>
</span></span><span style=display:flex><span><span style=color:#000>builder</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>extract_info</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>extract_type</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;property_graph&#34;</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span></code></pre></div></li><li><p><strong>Commit to HugeGraph</strong>: The <code>commit_to_hugegraph</code> method is used to commit the constructed knowledge graph to a HugeGraph instance.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000>builder</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>commit_to_hugegraph</span><span style=color:#000;font-weight:700>()</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span></code></pre></div></li><li><p><strong>Run</strong>: The <code>run</code> method is used to execute the chained operations.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000>builder</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>run</span><span style=color:#000;font-weight:700>()</span>
</span></span></code></pre></div><p>The methods of the <code>KgBuilder</code> class can be chained together to perform a sequence of operations.</p></li></ol><h3 id=42-retrieval-augmented-generation-rag-based-on-hugegraph>4.2 Retrieval augmented generation (RAG) based on HugeGraph</h3><p>The <code>RAGPipeline</code> class is used to integrate HugeGraph with large language models to provide retrieval-augmented generation capabilities.
Here is a brief usage guide:</p><ol><li><strong>Extract Keyword</strong>: Extract keywords and expand synonyms.<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>hugegraph_llm.operators.graph_rag_task</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>RAGPipeline</span>
</span></span><span style=display:flex><span><span style=color:#000>graph_rag</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>RAGPipeline</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span><span style=color:#000>graph_rag</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>extract_keywords</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>text</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;Tell me about Al Pacino.&#34;</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span></code></pre></div></li><li><strong>Match Vid from Keywords</strong>: Match the nodes with the keywords in the graph.<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000>graph_rag</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>keywords_to_vid</span><span style=color:#000;font-weight:700>()</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span></code></pre></div></li><li><strong>Query Graph for Rag</strong>: Retrieve the corresponding keywords and their multi-degree associated relationships from HugeGraph.<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000>graph_rag</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>query_graphdb</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>max_deep</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>2</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>max_graph_items</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>30</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span></code></pre></div></li><li><strong>Rerank Searched Result</strong>: Rerank the searched results based on the similarity between the question and the results.<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000>graph_rag</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>merge_dedup_rerank</span><span style=color:#000;font-weight:700>()</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span></code></pre></div></li><li><strong>Synthesize Answer</strong>: Summarize the results and organize the language to answer the question.<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000>graph_rag</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>synthesize_answer</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>vector_only_answer</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#204a87;font-weight:700>False</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>graph_only_answer</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#204a87;font-weight:700>True</span><span style=color:#000;font-weight:700>)</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>print_result</span><span style=color:#000;font-weight:700>()</span>
</span></span></code></pre></div></li><li><strong>Run</strong>: The <code>run</code> method is used to execute the above operations.<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000>graph_rag</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>run</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>verbose</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#204a87;font-weight:700>True</span><span style=color:#000;font-weight:700>)</span>
</span></span></code></pre></div></li></ol></div></div><div class=td-content style=page-break-before:always><h1 id=pg-bb10fc095f5061d789104547f7246a67>1 - GraphRAG UI Details</h1><blockquote><p>Follow up <a href=../>main doc</a> to introduce the basic UI function & details, welcome to update and improve at any time, thanks</p></blockquote><h1 id=1-core-logic-of-the-project>1. Core Logic of the Project</h1><h2 id=build-rag-index-responsibilities>Build RAG Index Responsibilities:</h2><ul><li>Split and vectorize text</li><li>Extract text into a graph (construct a knowledge graph) and vectorize the vertices</li></ul><h2 id=graphrag--user-functions-responsibilities>(Graph)RAG & User Functions Responsibilities:</h2><ul><li>Retrieve relevant content from the constructed knowledge graph and vector database based on the query to supplement the prompt.</li></ul><h1 id=2-processing-flow-build-rag-index>2. (Processing Flow) Build RAG Index</h1><p>Construct a knowledge graph, chunk vector, and graph vid vector from the text.</p><p><img src=https://github.com/user-attachments/assets/f3366d46-2e31-4638-94c4-7214951ef77a alt=image></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>graph TD;
</span></span><span style=display:flex><span>    A[Raw Text] --&gt; B[Text Segmentation]
</span></span><span style=display:flex><span>    B --&gt; C[Vectorization]
</span></span><span style=display:flex><span>    C --&gt; D[Store in Vector Database]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    A --&gt; F[Text Segmentation]
</span></span><span style=display:flex><span>    F --&gt; G[LLM extracts graph based on schema \nand segmented text]
</span></span><span style=display:flex><span>    G --&gt; H[Store graph in Graph Database, \nautomatically vectorize vertices \nand store in Vector Database]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    I[Retrieve vertices from Graph Database] --&gt; J[Vectorize vertices and store in Vector Database \nNote: Incremental update]
</span></span></code></pre></div><h3 id=four-input-fields>Four Input Fields:</h3><ul><li><strong>Doc(s):</strong> Input text</li><li><strong>Schema:</strong> The schema of the graph, which can be provided as a JSON-formatted schema or as the graph name (if it exists in the database).</li><li><strong>Graph</strong> <strong>Extract Prompt Header:</strong> The header of the prompt</li><li><strong>Output</strong>: Display results</li></ul><h3 id=buttons>Buttons:</h3><ul><li><p><strong>Get RAG Info</strong></p><ul><li><p><strong>Get Vector Index Info:</strong> Retrieve vector index information</p></li><li><p><strong>Get</strong> <strong>Graph</strong> <strong>Index Info:</strong> Retrieve graph index information</p></li></ul></li><li><p><strong>Clear RAG Data</strong></p><ul><li><strong>Clear Chunks Vector Index:</strong> Clear chunk vector</li><li><strong>Clear Graph Vid Vector Index</strong>: Clear graph vid vector</li><li><strong>Clear Graph Data</strong>: Clear Graph Data</li></ul></li><li><p><strong>Import into</strong> <strong>Vector</strong>: Convert the text in Doc(s) into vectors (requires chunking the text first and then converting the chunks into vectors)</p></li><li><p><strong>Extract</strong> <strong>Graph</strong> <strong>Data (1):</strong> Extract graph data from Doc(s) based on the Schema, using the Graph Extract Prompt Header and chunked content as the prompt</p></li><li><p><strong>Load into GraphDB (2):</strong> Store the extracted graph data into the database (automatically calls Update Vid Embedding to store vectors in the vector database)</p></li><li><p><strong>Update Vid Embedding:</strong> Convert graph vid into vectors</p></li></ul><h3 id=execution-flow>Execution Flow:</h3><ol><li>Input text into the <strong>Doc(s)</strong> field.</li><li>Click the <strong>Import into</strong> <strong>Vector</strong> button to split and vectorize the text, storing it in the vector database.</li><li>Input the graph <strong>Schema</strong> into the Schema field.</li><li>Click the <strong>Extract</strong> <strong>Graph</strong> <strong>Data (1)</strong> button to extract the text into a graph.</li><li>Click the <strong>Load into GraphDB (2)</strong> button to store the extracted graph into the graph database (this automatically calls <strong>Update Vid Embedding</strong> to store the vectors in the vector database).</li><li>Click the <strong>Update</strong> <strong>Vid</strong> <strong>Embedding</strong> button to vectorize the graph vertices and store them in the vector database.</li></ol><h1 id=3-processing-flow-graphrag--user-functions>3. (Processing Flow) (Graph)RAG & User Functions</h1><p>The <strong>Import into</strong> <strong>Vector</strong> button in the previous module converts text (chunks) into vectors, and the <strong>Update Vid Embedding</strong> button converts graph vid into vectors. These vectors are stored separately to supplement the context for queries (answer generation) in this module. In other words, the previous module prepares the data for RAG (vectorization), while this module executes RAG.</p><p>This module consists of two parts:</p><ul><li><strong>HugeGraph RAG</strong> <strong>Query</strong></li><li><strong>(Batch) Back-testing</strong></li></ul><p>The first part handles single queries, while the second part handles multiple queries at once. Below is an explanation of the first part.</p><p><img src=https://github.com/user-attachments/assets/33698062-e46b-4757-8b5e-93e8f10eae65 alt=image></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>graph TD;
</span></span><span style=display:flex><span>    A[Question] --&gt; B[Vectorize the question and search \nfor the most similar chunk in the Vector Database &amp;#40chunk&amp;#41]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    A --&gt; F[Extract keywords using LLM]
</span></span><span style=display:flex><span>    F --&gt; G[Match vertices precisely in Graph Database \nusing keywords; perform fuzzy matching in \nVector Database &amp;#40graph vid&amp;#41]
</span></span><span style=display:flex><span>    G --&gt; H[Generate Gremlin query using matched vertices and query with LLM]
</span></span><span style=display:flex><span>    H --&gt; I[Execute Gremlin query; if successful, finish; if failed, fallback to BFS]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    B --&gt; J[Sort results]
</span></span><span style=display:flex><span>    I --&gt; J
</span></span><span style=display:flex><span>    J --&gt; K[Generate answer]
</span></span></code></pre></div><h3 id=input-fields>Input Fields:</h3><ul><li><strong>Question:</strong> Input the query</li><li><strong>Query</strong> <strong>Prompt:</strong> The prompt template used to ask the final question to the LLM</li><li><strong>Keywords Extraction Prompt:</strong> The prompt template for extracting keywords from the question</li><li><strong>Template Num:</strong> &lt; 0 means disable text2gql; = 0 means no template(zero-shot); > 0 means using the specified number of templates</li></ul><h3 id=query-scope-selection>Query Scope Selection:</h3><ul><li><strong>Basic</strong> <strong>LLM</strong> <strong>Answer:</strong> Does not use RAG functionality</li><li><strong>Vector-only Answer:</strong> Uses only vector-based retrieval (queries chunk vectors in the vector database)</li><li><strong>Graph-only Answer:</strong> Uses only graph-based retrieval (queries graph vid vectors in the vector database and the graph database)</li><li><strong>Graph-Vector Answer:</strong> Uses both graph-based and vector-based retrieval</li></ul><p><img src=https://github.com/user-attachments/assets/26641e09-249f-4b3a-8013-16dc9383d333 alt=image></p><h3 id=execution-flow-1>Execution Flow:</h3><h4 id=graph-only-answer><strong>Graph-only Answer:</strong></h4><ul><li>Extract keywords from the <strong>question</strong> using the <strong>Keywords Extraction Prompt</strong>.</li></ul><p><img src=https://github.com/user-attachments/assets/b49e269f-eaec-40b1-8d8f-9e409821d75d alt=image></p><ul><li><p>Use the extracted keywords to:</p><ul><li><p>First, perform an exact match in the graph database.</p></li><li><p>If no match is found, perform a fuzzy match in the vector database (graph vid vector) to retrieve relevant vertices.</p></li></ul></li><li><p><strong>text2gql:</strong> Call the text2gql-related interface, using the matched vertices as entities to convert the <strong>question</strong> into a Gremlin query and execute it in the graph database.</p></li><li><p><strong>BFS:</strong> If text2gql fails (LLM-generated queries might be invalid), fall back to executing a graph query using a predefined <strong>Gremlin query template</strong> (essentially a BFS traversal).</p></li></ul><h4 id=vector-only-answer><strong>Vector-only Answer:</strong></h4><ul><li><p>Convert the <strong>query</strong> into a vector.</p></li><li><p>Search for the most similar content in the <strong>chunk vector</strong> dataset in the vector database.</p></li></ul><h4 id=sorting-and-answer-generation><strong>Sorting and Answer Generation:</strong></h4><ul><li><p>After executing the retrieval, sort the search (retrieval) results to construct the final <strong>prompt</strong>.</p></li><li><p>Generate answers based on different prompt configurations and display them in different output fields:</p><ul><li><strong>Basic</strong> <strong>LLM</strong> <strong>Answer</strong></li><li><strong>Vector-only Answer</strong></li><li><strong>Graph-only Answer</strong></li><li><strong>Graph-Vector Answer</strong></li></ul></li></ul><p><img src=https://github.com/user-attachments/assets/7d4496a3-d44c-4491-9463-8e93595dfa45 alt=image></p><h1 id=4-processing-flow-text2gremlin>4. (Processing Flow) Text2Gremlin</h1><p>Converts natural language queries into Gremlin queries.</p><p>This module consists of two parts:</p><ul><li><strong>Build</strong> <strong>Vector</strong> <strong>Template Index (Optional):</strong> Vectorizes query/gremlin pairs from sample files and stores them in the vector database for reference when generating Gremlin queries.</li><li><strong>Natural Language to Gremlin:</strong> Converts natural language queries into Gremlin queries.</li></ul><p>The first part is straightforward, so the focus is on the second part.</p><p><img src=https://github.com/user-attachments/assets/fc678369-261d-49ea-a289-1ca6ade5ca55 alt=image></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>graph TD;
</span></span><span style=display:flex><span>    A[Gremlin Pairs File] --&gt; C[Vectorize query]
</span></span><span style=display:flex><span>    C --&gt; D[Store in Vector Database]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    F[Natural Language Query] --&gt; G[Search for the most similar query \nin the Vector Database \n&amp;#40If no Gremlin pairs exist in the Vector Database, \ndefault files will be automatically vectorized&amp;#41 \nand retrieve the corresponding Gremlin]
</span></span><span style=display:flex><span>    G --&gt; H[Add the matched pair to the prompt \nand use LLM to generate the Gremlin \ncorresponding to the Natural Language Query]
</span></span></code></pre></div><h3 id=input-fields-for-the-second-part>Input Fields for the Second Part:</h3><ul><li><strong>Natural Language</strong> <strong>Query</strong>: Input the natural language text to be converted into Gremlin.</li></ul><p><img src=https://github.com/user-attachments/assets/d2a72f45-488c-4099-968b-a11816655ba0 alt=image></p><ul><li><strong>Schema:</strong> Input the graph schema.</li></ul><h3 id=execution-flow-2>Execution Flow:</h3><ol><li><p>Input the <strong>query</strong> (natural language) into the <strong>Natural Language Query</strong> field.</p></li><li><p>Input the <strong>graph</strong> <strong>schema</strong> into the <strong>Schema</strong> field.</p></li><li><p>Click the <strong>Text2Gremlin</strong> button, and the following execution logic applies:</p><ol><li><p>Convert the <strong>query</strong> into a vector.</p></li><li><p>Construct the <strong>prompt</strong>:</p><ul><li>Retrieve the <strong>graph schema</strong>.</li><li>Query the vector database for example vectors, retrieving query-gremlin pairs similar to the input query (if the vector database lacks examples, it automatically initializes with examples from the <strong>resources</strong> folder).</li></ul></li></ol></li></ol><p><img src=https://github.com/user-attachments/assets/fd150f87-27f8-48e5-8a55-319ec039b7e0 alt=image></p><pre><code>  - Generate the Gremlin query using the constructed prompt.
</code></pre><h1 id=5-graph-tools>5. Graph Tools</h1><p>Input Gremlin queries to execute corresponding operations.</p></div></main></div></div><footer class="bg-dark py-3 row d-print-none"><div class=footer-container><div class="row bg-dark"><div class=col-1></div><div class="col-4 text-center container-center"><div class=footer-row><a href=https://incubator.apache.org/><div class=footer-apache-logo><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 473.26 110.22"><defs><style>.cls-1,.cls-2{fill:#fff}.cls-1{fill-rule:evenodd}</style></defs><g id="Layer_2" data-name="Layer 2"><g id="Layer_1-2" data-name="Layer 1"><polygon class="cls-1" points="445.81 13.29 467.03 13.29 467.03 15.29 448.03 15.29 448.03 27.09 465.11 27.09 465.11 29.09 448.03 29.09 448.03 41.1 467.24 41.1 467.24 43.11 445.81 43.11 445.81 13.29"/><polygon class="cls-1" points="377.65 13.29 379.86 13.29 379.86 27.13 398.95 27.13 398.95 13.29 401.16 13.29 401.16 43.11 398.95 43.11 398.95 29.13 379.86 29.13 379.86 43.11 377.65 43.11 377.65 13.29"/><path class="cls-1" d="M323.93 43.62a14.55 14.55.0 01-10.63-4.45 14.92 14.92.0 01-3.09-4.88 16.21 16.21.0 01-1.11-6V28.2a15.89 15.89.0 014.24-10.89A14.42 14.42.0 01324 12.78a17.34 17.34.0 013.62.34 14 14 0 013 1 15.6 15.6.0 012.6 1.51 23.56 23.56.0 012.36 1.94L334 19.17a24 24 0 00-2-1.75A12.58 12.58.0 00329.7 16 13.11 13.11.0 00324 14.78a12.11 12.11.0 00-9 3.85 13.55 13.55.0 00-2.64 4.24 14.15 14.15.0 00-1 5.24v.09a14.1 14.1.0 001 5.26 13.67 13.67.0 002.67 4.26 12.2 12.2.0 004 2.85 11.83 11.83.0 005 1 12.39 12.39.0 005.63-1.2A17.89 17.89.0 00334.28 37l1.49 1.45a26.6 26.6.0 01-2.45 2.11 15 15 0 01-2.68 1.64 14.81 14.81.0 01-3.09 1.07A16.42 16.42.0 01323.93 43.62z"/><path class="cls-1" d="M252.32 13.07h2.13l13.89 30h-2.43l-3.79-8.35h-17.6l-3.79 8.35h-2.3l13.89-30zm8.86 19.69-7.84-17.26-7.88 17.26z"/><path class="cls-1" d="M176.74 13.29h10.82a15.11 15.11.0 014.5.62 10.36 10.36.0 013.49 1.78 8.21 8.21.0 012.28 2.86 8.78 8.78.0 01.81 3.85v.09a8.56 8.56.0 01-3.47 7.11 11.22 11.22.0 01-3.71 1.79A16.16 16.16.0 01187 32h-8V43.11h-2.22V13.29zM187.14 30a13.21 13.21.0 003.79-.51A8.65 8.65.0 00193.85 28a6.76 6.76.0 001.89-2.33 6.66 6.66.0 00.69-3v-.09a7 7 0 00-.67-3.15 6.12 6.12.0 00-1.85-2.25 8.68 8.68.0 00-2.85-1.37 13.6 13.6.0 00-3.67-.47H179V30z"/><path class="cls-1" d="M118.64 13.07h2.13l13.88 30h-2.42l-3.8-8.35H110.84l-3.79 8.35h-2.3l13.89-30zm8.86 19.69-7.84-17.26-7.88 17.26z"/><path class="cls-1" d="M471.26 70.85q0 10.83-9.44 13.64l11.44 15.88h-9.38L453.44 85.68h-9.7v14.69h-7.38V56.66h16.27q10 0 14.32 3.37t4.31 10.82zM452.94 79q6.26.0 8.5-1.93c1.5-1.3 2.25-3.37 2.25-6.23s-.77-4.81-2.31-5.88-4.29-1.59-8.25-1.59h-9.39V79z"/><path class="cls-1" d="M422.13 94.34a24 24 0 01-32.77.0 21.65 21.65.0 01-6.63-16.14 21.61 21.61.0 016.63-16.13 24 24 0 0132.77.0 21.61 21.61.0 016.63 16.13 21.65 21.65.0 01-6.63 16.14zM416.72 67a15.32 15.32.0 00-22 0 16.33 16.33.0 000 22.45 15.32 15.32.0 0022 0 16.33 16.33.0 000-22.45z"/><polygon class="cls-1" points="367.18 63.41 367.18 100.37 359.8 100.37 359.8 63.41 346.54 63.41 346.54 56.66 380.44 56.66 380.44 63.41 367.18 63.41"/><path class="cls-1" d="M315.61 90.43l-4.38 9.94h-7.88l19.27-43.71h7.88l19.26 43.71h-7.88l-4.38-9.94zm18.89-6.82-7.94-18-7.95 18z"/><path class="cls-1" d="M286.62 100.37H267.48V56.66h17a24.47 24.47.0 017.66 1.06 10.56 10.56.0 014.79 2.88 11.17 11.17.0 013 7.63c0 3.42-1.09 6-3.25 7.63A14.58 14.58.0 01295.06 77q-.44.22-1.56.72a11.54 11.54.0 016.5 3.61 10.23 10.23.0 012.41 6.91 11.76 11.76.0 01-3.13 8.07q-3.69 4.06-12.63 4.06zm-11.76-6.81h11.57a12.25 12.25.0 006.22-1.29c1.44-.85 2.16-2.47 2.16-4.84q0-5.82-9.32-5.82H274.86v12zm0-18.77h9.38q8 0 8-5.44a5.15 5.15.0 00-1.94-4.5c-1.29-.92-3.3-1.38-6-1.38h-9.44V74.79z"/><path class="cls-1" d="M231 90.37a11.19 11.19.0 0016.26.0q3-3.51 3-9.51V56.66h7.38V81.17q0 9.45-5.19 14.54a19.94 19.94.0 01-26.64.0q-5.19-5.08-5.19-14.54V56.66H228v24.2Q228 86.86 231 90.37z"/><path class="cls-1" d="M196.8 93.68a15.48 15.48.0 006.56-1.28 22.58 22.58.0 005.76-4.1l4.75 4.88A21.87 21.87.0 01197 100.87a22.57 22.57.0 01-16.45-6.38A21.58 21.58.0 01174 78.36a21.78 21.78.0 016.66-16.26q6.66-6.51 16.83-6.51a22 22 0 0117 7.51l-4.69 5.13A20.41 20.41.0 00203.9 64a16.46 16.46.0 00-6.54-1.19 15.54 15.54.0 00-11.13 4.28 14.48 14.48.0 00-4.51 11 15.12 15.12.0 004.48 11.13A14.48 14.48.0 00196.8 93.68z"/><polygon class="cls-1" points="159.05 56.66 166.43 56.66 166.43 100.37 158.42 100.37 133.66 68.48 133.66 100.37 126.28 100.37 126.28 56.66 133.66 56.66 159.05 89.3 159.05 56.66"/><rect class="cls-2" x="108.48" y="56.66" width="7.38" height="43.72"/><path class="cls-1" d="M44.92 15.1c0-.32.0-.64.0-1l.57 1zM33.16 49.33a49.36 49.36.0 00-5.89 20c-.44 6.17.22 11.49 2 16 .25.61.49 1.17.72 1.69q-2.13-1.52-4.07-3.15c-.11-.09-.19-.12-.24-.11a32.87 32.87.0 006.36 7.39c.39.34 1 .5 1.2 1 .46 1.45-.79 14.4 3.22 17.42 2.55 1.92 13.82-.49 17.3-1.62C71.92 102 86 85.26 83.9 61.11 81.61 34.62 64.16 7.68 46.75 1.2 42-.55 41-.39 36.11 1.7 19.13 9 2.45 35.25.21 61.11-1.95 86 13 103 31.9 108.36l1.48.41a19.49 19.49.0 01-1.2-3.36C12.38 99.52 1.31 82 3.1 61.36 4.81 41.65 18 12.6 37.25 4.37c4-1.72 4.41-2 8.48-.44C65.48 11.27 79.27 41.32 81 61.36 82.86 82.78 70.78 100.81 49.89 106a39.89 39.89.0 01-5.62 1c-5.42.55-7.3 1.5-8.29-4.13-2.19-12.44-.54-34.94 4.87-43.57a9.4 9.4.0 01-.4 1.5c-.18.44-.31.71-.36.85-3.24 7.42-5.05 28.95-3.5 33-.45-1.46.35-4.55 1.51-5.18l.66-.47c3.63-2.61 6-6.71 8.59-11.91.0-.07-.13-.07-.25.0a33.72 33.72.0 01-3.78 2.76A43.06 43.06.0 0051.06 68c-.06-.09-.16-.07-.31.0-.87.79-1.76 1.53-2.67 2.23 3.71-6.72 7-14.49 7.32-23.38a38.61 38.61.0 00-3.16-16.59c-.78-1.81-1.88-4-3.29-6.53C46.86 20 45.73 18 45.55 17.7c.1 8.15-1.34 14.78-4.31 19.84a60.7 60.7.0 01-4.09 5.86 46.12 46.12.0 00-3.99 5.93z"/></g></g></svg></div></a><ul class=footer-link><li><a class=white href=https://www.apache.org>Foundation</a></li><li><a class=white href=https://www.apache.org/licenses/>License</a></li><li><a class=white href=https://hugegraph.apache.org/docs/guides/security>Security</a></li><li><a class=white href=https://www.apache.org/events/current-event>Events</a></li><li><a class=white href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a></li><li><a class=white href=https://www.apache.org/foundation/thanks.html>Thanks</a></li><li><a class=white href=https://privacy.apache.org/policies/privacy-policy-public.html target=_blank>Privacy</a></li></ul></div></div><div class="col-6 text-white text-center container-center"><p>Apache HugeGraph is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.</p><p>Copyright &copy; 2025 The Apache Software Foundation, Licensed under the <a class=white href=https://www.apache.org/licenses/LICENSE-2.0>Apache License Version 2.0</a><br>Apache, the names of Apache projects, and the feather logo are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries.</p></div><div class=col-1></div></div></div></footer></div><script src=/js/popper.min.js></script>
<script src=/js/bootstrap.min.js></script>
<script src=/js/tabpane-persist.js></script>
<script src=/js/main.min.aa9f4c5dae6a98b2c46277f4c56f1673a2b000d1756ce4ffae93784cab25e6d5.js integrity="sha256-qp9MXa5qmLLEYnf0xW8Wc6KwANF1bOT/rpN4TKsl5tU=" crossorigin=anonymous></script>
<script src=/js/prism.js></script></body></html>