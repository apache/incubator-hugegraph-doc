---
title: "HugeGraphå·¥å…·é“¾æœ¬åœ°æµ‹è¯•æŒ‡å—"
linkTitle: "Toolchainæœ¬åœ°æµ‹è¯•"
weight: 4
---

æœ¬æŒ‡å—å¸®åŠ©å¼€å‘è€…åœ¨æœ¬åœ°è¿è¡Œ HugeGraph å·¥å…·é“¾æµ‹è¯•ã€‚

## 1. æ ¸å¿ƒæ¦‚å¿µ

### 1.1 æ ¸å¿ƒä¾èµ–ï¼šHugeGraph Server

**å·¥å…·é“¾çš„é›†æˆæµ‹è¯•å’ŒåŠŸèƒ½æµ‹è¯•éƒ½ä¾èµ– HugeGraph Server**ï¼ŒåŒ…æ‹¬ Clientã€Loaderã€Hubbleã€Spark Connectorã€Tools ç­‰ç»„ä»¶ã€‚

### 1.2 æµ‹è¯•ç±»å‹

- **å•å…ƒæµ‹è¯• (Unit Tests)**ï¼šæµ‹è¯•å•ä¸ªå‡½æ•°/æ–¹æ³•ï¼Œä¸ä¾èµ–å¤–éƒ¨æœåŠ¡
- **API æµ‹è¯• (ApiTestSuite)**ï¼šæµ‹è¯• API æ¥å£ï¼Œéœ€è¦è¿è¡Œä¸­çš„ HugeGraph Server
- **åŠŸèƒ½æµ‹è¯• (FuncTestSuite)**ï¼šç«¯åˆ°ç«¯æµ‹è¯•ï¼Œéœ€è¦å®Œæ•´çš„ç³»ç»Ÿç¯å¢ƒ

## 2. ç¯å¢ƒå‡†å¤‡

### 2.1 ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**ï¼šLinux / macOSï¼ˆWindows ä½¿ç”¨ WSL2ï¼‰
- **JDK**ï¼š>= 11ï¼Œé…ç½®å¥½ `JAVA_HOME`
- **Maven**ï¼š>= 3.5
- **Python**ï¼š>= 3.11ï¼ˆä»… Hubble æµ‹è¯•éœ€è¦ï¼‰

### 2.2 å…‹éš†ä»£ç 

```bash
git clone https://github.com/${GITHUB_USER_NAME}/hugegraph-toolchain.git
cd hugegraph-toolchain
```

## 3. éƒ¨ç½²æµ‹è¯•ç¯å¢ƒ

### æ–¹å¼é€‰æ‹©

- **è„šæœ¬éƒ¨ç½²ï¼ˆæ¨èï¼‰**ï¼šé€šè¿‡æŒ‡å®š Commit ID ç²¾ç¡®æ§åˆ¶ Server ç‰ˆæœ¬ï¼Œé¿å…æ¥å£ä¸å…¼å®¹
- **Docker éƒ¨ç½²**ï¼šå¿«é€Ÿå¯åŠ¨ï¼Œä½†å¯èƒ½ç‰ˆæœ¬æ»åå¯¼è‡´æµ‹è¯•å¤±è´¥

> è¯¦ç»†å®‰è£…è¯´æ˜å‚è€ƒ [ç¤¾åŒºæ–‡æ¡£](https://hugegraph.apache.org/cn/docs/quickstart/hugegraph/hugegraph-server/)

### 3.1 è„šæœ¬éƒ¨ç½²ï¼ˆæ¨èï¼‰

#### å‚æ•°è¯´æ˜

- **`$COMMIT_ID`**ï¼šæŒ‡å®š Server æºç çš„ Git Commit ID
- **`$DB_DATABASE` / `$DB_PASS`**ï¼šLoader JDBC æµ‹è¯•ç”¨çš„ MySQL æ•°æ®åº“åå’Œå¯†ç 

#### éƒ¨ç½²æ­¥éª¤

**1. å®‰è£… HugeGraph Server**

```bash
# è®¾ç½®ç‰ˆæœ¬
export COMMIT_ID="master"  # æˆ–ç‰¹å®š commit hashï¼Œå¦‚ "8b90977"

# æ‰§è¡Œå®‰è£…ï¼ˆè„šæœ¬ä½äº /assembly/travis/ ç›®å½•ï¼‰
hugegraph-client/assembly/travis/install-hugegraph-from-source.sh $COMMIT_ID
```

- é»˜è®¤ç«¯å£ï¼šhttp 8080, https 8443
- ç¡®ä¿ç«¯å£æœªè¢«å ç”¨

**2. å®‰è£…å¯é€‰ä¾èµ–**

```bash
# Hadoop (ä»… Loader HDFS æµ‹è¯•éœ€è¦)
hugegraph-loader/assembly/travis/install-hadoop.sh

# MySQL (ä»… Loader JDBC æµ‹è¯•éœ€è¦)
hugegraph-loader/assembly/travis/install-mysql.sh $DB_DATABASE $DB_PASS
```

**3. å¥åº·æ£€æŸ¥**

```bash
curl http://localhost:8080/graphs
# è¿”å› {"graphs":["hugegraph"]} è¡¨ç¤ºæˆåŠŸ
```

### 3.2 Docker éƒ¨ç½²

> **æ³¨æ„**ï¼šDocker é•œåƒå¯èƒ½ç‰ˆæœ¬æ»åï¼Œå¦‚é‡å…¼å®¹æ€§é—®é¢˜è¯·ä½¿ç”¨è„šæœ¬éƒ¨ç½²

#### å¿«é€Ÿå¯åŠ¨

```bash
docker network create hugegraph-net
docker run -itd --name=server -p 8080:8080 --network hugegraph-net hugegraph/hugegraph:latest
```

#### docker-compose é…ç½®ï¼ˆå¯é€‰ï¼‰

å®Œæ•´é…ç½®ç¤ºä¾‹ï¼ŒåŒ…å« Serverã€MySQLã€Hadoop æœåŠ¡ï¼ˆéœ€è¦ Docker Compose V2ï¼‰ï¼š

```yaml
version: '3.8'

services:
  hugegraph-server:
    image: hugegraph/hugegraph:latest  # å¯ä»¥æ›¿æ¢ä¸ºç‰¹å®šç‰ˆæœ¬ï¼Œæˆ–æ„å»ºè‡ªå·±çš„é•œåƒ
    container_name: hugegraph-server
    ports:
      - "8080:8080"  # HugeGraph Server HTTP ç«¯å£
    environment:
      # æ ¹æ®éœ€è¦é…ç½®HugeGraph Serverçš„å‚æ•°ï¼Œä¾‹å¦‚åç«¯å­˜å‚¨
      - HUGEGRAPH_SERVER_OPTIONS="-Dstore.backend=rocksdb"
    volumes:
      # å¦‚æœéœ€è¦æŒä¹…åŒ–æ•°æ®æˆ–æŒ‚è½½é…ç½®æ–‡ä»¶ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å·
      # - ./hugegraph-data:/opt/hugegraph/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/graphs || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - hugegraph-net
  
  # å¦‚æœéœ€è¦hugegraph-loaderçš„JDBCæµ‹è¯•ï¼Œå¯ä»¥æ·»åŠ ä»¥ä¸‹æœåŠ¡
  #   mysql:
  #     image: mysql:5.7
  #     container_name: mysql-db
  #     environment:
  #       MYSQL_ROOT_PASSWORD: ${DB_PASS:-your_mysql_root_password} # ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼
  #       MYSQL_DATABASE: ${DB_DATABASE:-hugegraph_test_db} # ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼
  #     ports:
  #       - "3306:3306"
  #     volumes:
  #       - ./mysql-data:/var/lib/mysql # æ•°æ®æŒä¹…åŒ–
  #     healthcheck:
  #       test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-p${DB_PASS:-your_mysql_root_password}"]
  #       interval: 5s
  #       timeout: 3s
  #       retries: 5
  #     networks:
  #       - hugegraph-net

  # å¦‚æœéœ€è¦hugegraph-loaderçš„Hadoop/HDFSæµ‹è¯•ï¼Œå¯ä»¥æ·»åŠ ä»¥ä¸‹æœåŠ¡
  #   namenode:
  #     image: johannestang/hadoop-namenode:2.0.0-hadoop2.8.5-java8
  #     container_name: namenode
  #     ports:
  #       - "0.0.0.0:9870:9870"
  #       - "0.0.0.0:8020:8020"
  #     environment:
  #       - CLUSTER_NAME=test-cluster
  #       - HDFS_NAMENODE_USER=root
  #       - HADOOP_CONF_DIR=/hadoop/etc/hadoop
  #     volumes:
  #       - ./config/core-site.xml:/hadoop/etc/hadoop/core-site.xml
  #       - ./config/hdfs-site.xml:/hadoop/etc/hadoop/hdfs-site.xml
  #       - namenode_data:/hadoop/dfs/name
  #     command: bash -c "if [ ! -d /hadoop/dfs/name/current ]; then hdfs namenode -format; fi && /entrypoint.sh"
  #     healthcheck:
  #       test: ["CMD", "hdfs", "dfsadmin", "-report"]
  #       interval: 5s
  #       timeout: 3s
  #       retries: 5
  #     networks:
  #       - hugegraph-net

  #   datanode:
  #     image: johannestang/hadoop-datanode:2.0.0-hadoop2.8.5-java8
  #     container_name: datanode
  #     depends_on:
  #       - namenode
  #     environment:
  #       - CLUSTER_NAME=test-cluster
  #       - HDFS_DATANODE_USER=root
  #       - HADOOP_CONF_DIR=/hadoop/etc/hadoop
  #     volumes:
  #       - ./config/core-site.xml:/hadoop/etc/hadoop/core-site.xml
  #       - ./config/hdfs-site.xml:/hadoop/etc/hadoop/hdfs-site.xml
  #       - datanode_data:/hadoop/dfs/data
  #     healthcheck:
  #       test: ["CMD", "hdfs", "dfsadmin", "-report"]
  #       interval: 5s
  #       timeout: 3s
  #       retries: 5
  #     networks:
  #       - hugegraph-net

networks:
  hugegraph-net:
    driver: bridge
volumes:
  namenode_data:
  datanode_data:
```

#### Hadoop é…ç½®æŒ‚è½½
`./config`æ–‡ä»¶å¤¹ç”¨äºé…ç½®æŒ‚è½½ï¼Œè¯·è‡ªè¡Œé€‰æ‹©æ˜¯å¦è®¾ç½®ï¼Œéœ€è¦ä¸ `docker-compose.yml` ä½äºåŒä¸€æ–‡ä»¶å¤¹

ğŸ“ ./config/core-site.xml å†…å®¹ï¼š

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://namenode:8020</value>
    </property>
</configuration>
```

ğŸ“ ./config/hdfs-site.xml å†…å®¹ï¼š

```xml
<configuration>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/hadoop/hdfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/hadoop/hdfs/data</value>
    </property>
    <property>
        <name>dfs.permissions.superusergroup</name>
        <value>hadoop</value>
    </property>
    <property>
        <name>dfs.support.append</name>
        <value>true</value>
    </property>
</configuration>
```

#### Docker æ“ä½œ

```bash
# å¯åŠ¨æœåŠ¡
docker compose up -d

# æ£€æŸ¥çŠ¶æ€
docker compose ps
lsof -i:8080  # Server
lsof -i:8020  # Hadoop
lsof -i:3306  # MySQL

# åœæ­¢æœåŠ¡
docker compose down
```

## 4. è¿è¡Œæµ‹è¯•

å„å·¥å…·çš„æµ‹è¯•æµç¨‹ï¼š

<div style="text-align: center;">
    <img src="/docs/images/toolchain-test-mermaid-2.png" alt="HugeGraphå·¥å…·é“¾æµ‹è¯•æµç¨‹å›¾">
</div>

### 4.1 hugegraph-client

#### ç¼–è¯‘

```bash
mvn -e compile -pl hugegraph-client -Dmaven.javadoc.skip=true -ntp
```

#### ä¾èµ–æœåŠ¡

å¯åŠ¨ HugeGraph Serverï¼ˆå‚è€ƒ [ç¬¬3èŠ‚](#3-éƒ¨ç½²æµ‹è¯•ç¯å¢ƒ)ï¼‰

##### Server é‰´æƒé…ç½®

> **æ³¨æ„**ï¼šDocker é•œåƒ <= 1.5.0 ä¸æ”¯æŒé‰´æƒæµ‹è¯•ï¼Œéœ€ 1.6.0+

ApiTest éœ€è¦é‰´æƒé…ç½®ï¼Œä½¿ç”¨è„šæœ¬å®‰è£…å¯è·³è¿‡ã€‚ä½¿ç”¨ Docker éœ€æ‰‹åŠ¨é…ç½®ï¼š

```bash
# 1. ä¿®æ”¹é‰´æƒæ¨¡å¼
cp conf/rest-server.properties conf/rest-server.properties.backup
sed -i '/^auth.authenticator=/c\auth.authenticator=org.apache.hugegraph.auth.StandardAuthenticator' conf/rest-server.properties
grep auth.authenticator conf/rest-server.properties

# 2. è®¾ç½®å¯†ç 
# æ³¨ï¼šæµ‹è¯•ä»£ç ä¸­é»˜è®¤ä½¿ç”¨ "pa" ä½œä¸ºå¯†ç ï¼Œè®¾ç½®æ—¶éœ€ä¸æµ‹è¯•ä¿æŒä¸€è‡´
bin/stop-hugegraph.sh
export PASSWORD="pa"  # è®¾ç½®ä¸ºæµ‹è¯•é»˜è®¤å¯†ç 
echo -e "${PASSWORD}" | bin/init-store.sh
bin/start-hugegraph.sh
```

#### è¿è¡Œæµ‹è¯•

```bash
# æ£€æŸ¥ç¯å¢ƒ
curl http://localhost:8080/graphs  # åº”è¿”å› {"graphs":["hugegraph"]}
curl -u admin:pa http://localhost:8080/graphs  # é‰´æƒæµ‹è¯•ï¼ˆå¯†ç  pa æ˜¯æµ‹è¯•é»˜è®¤å€¼ï¼‰

# è¿è¡Œæµ‹è¯•
cd hugegraph-client
mvn test -Dtest=UnitTestSuite -ntp      # å•å…ƒæµ‹è¯•
mvn test -Dtest=ApiTestSuite -ntp       # APIæµ‹è¯•ï¼ˆéœ€ Serverï¼‰
mvn test -Dtest=FuncTestSuite -ntp      # åŠŸèƒ½æµ‹è¯•ï¼ˆéœ€ Serverï¼‰
```

> æµ‹è¯•å¤±è´¥æ—¶æ£€æŸ¥ Server æ—¥å¿—ï¼š`logs/hugegraph-server.log`

### 4.2 hugegraph-loader

#### ç¼–è¯‘

```bash
mvn install -pl hugegraph-client,hugegraph-loader -am -Dmaven.javadoc.skip=true -DskipTests -ntp
```

#### ä¾èµ–æœåŠ¡

- **å¿…éœ€**ï¼šHugeGraph Server
- **å¯é€‰**ï¼šHadoop (HDFS æµ‹è¯•)ã€MySQL (JDBC æµ‹è¯•)

#### è¿è¡Œæµ‹è¯•

```bash
cd hugegraph-loader
mvn test -P unit -ntp   # å•å…ƒæµ‹è¯•
mvn test -P file -ntp   # æ–‡ä»¶æµ‹è¯•ï¼ˆéœ€ Serverï¼‰
mvn test -P hdfs -ntp   # HDFSæµ‹è¯•ï¼ˆéœ€ Server + Hadoopï¼‰
mvn test -P jdbc -ntp   # JDBCæµ‹è¯•ï¼ˆéœ€ Server + MySQLï¼‰
mvn test -P kafka -ntp  # Kafkaæµ‹è¯•ï¼ˆéœ€ Serverï¼‰
```

### 4.3 hugegraph-hubble

#### ç¼–è¯‘

```bash
mvn install -pl hugegraph-client,hugegraph-loader -am -Dmaven.javadoc.skip=true -DskipTests -ntp
cd hugegraph-hubble
mvn -e compile -Dmaven.javadoc.skip=true -ntp
```

#### ä¾èµ–æœåŠ¡

**1. å¯åŠ¨ Server**ï¼ˆå‚è€ƒ [ç¬¬3èŠ‚](#3-éƒ¨ç½²æµ‹è¯•ç¯å¢ƒ)ï¼‰

**2. Python ç¯å¢ƒ**

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
python -m pip install -r hubble-dist/assembly/travis/requirements.txt
```

**3. æ„å»ºå¹¶éªŒè¯**

```bash
mvn package -Dmaven.test.skip=true
# å¯é€‰ï¼šå¯åŠ¨éªŒè¯
cd apache-hugegraph-hubble-incubating-*/bin
./start-hubble.sh -d && sleep 10
curl http://localhost:8088/api/health
./stop-hubble.sh
```

#### è¿è¡Œæµ‹è¯•

```bash
# å•å…ƒæµ‹è¯•
mvn test -P unit-test -pl hugegraph-hubble/hubble-be -ntp

# APIæµ‹è¯•ï¼ˆéœ€ Server + Hubble è¿è¡Œï¼‰
curl http://localhost:8080/graphs  # æ£€æŸ¥ Server
curl http://localhost:8088/api/health  # æ£€æŸ¥ Hubble
cd hugegraph-hubble/hubble-dist
./assembly/travis/run-api-test.sh
```

### 4.4 hugegraph-spark-connector

#### ç¼–è¯‘

```bash
mvn install -pl hugegraph-client,hugegraph-spark-connector -am -Dmaven.javadoc.skip=true -DskipTests -ntp
```

#### è¿è¡Œæµ‹è¯•

```bash
cd hugegraph-spark-connector
mvn test -ntp  # éœ€ Server è¿è¡Œ
```

### 4.5 hugegraph-tools

#### ç¼–è¯‘

```bash
mvn install -pl hugegraph-client,hugegraph-tools -am -Dmaven.javadoc.skip=true -DskipTests -ntp
```

#### è¿è¡Œæµ‹è¯•

```bash
cd hugegraph-tools
mvn test -Dtest=FuncTestSuite -ntp  # éœ€ Server è¿è¡Œ
```

## 5. å¸¸è§é—®é¢˜

### æœåŠ¡è¿æ¥é—®é¢˜

**ç—‡çŠ¶**ï¼šæ— æ³•è¿æ¥ Server/MySQL/Hadoop

**æ’æŸ¥**ï¼š
- ç¡®è®¤æœåŠ¡å·²å¯åŠ¨ï¼ˆServer å¿…é¡»åœ¨ 8080 ç«¯å£ï¼‰
- æ£€æŸ¥ç«¯å£å ç”¨ï¼š`lsof -i:8080`
- Docker æ£€æŸ¥ï¼š`docker compose ps` å’Œ `docker compose logs`

### é…ç½®é—®é¢˜

**ç—‡çŠ¶**ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ã€å‚æ•°é”™è¯¯

**æ’æŸ¥**ï¼š
- æ£€æŸ¥ç¯å¢ƒå˜é‡ï¼š`echo $COMMIT_ID`
- è„šæœ¬æƒé™ï¼š`chmod +x hugegraph-*/assembly/travis/*.sh`

### HDFS æµ‹è¯•å¤±è´¥

**æ’æŸ¥**ï¼š
- ç¡®è®¤ NameNode/DataNode è¿è¡Œæ­£å¸¸
- æ£€æŸ¥ Hadoop æ—¥å¿—
- éªŒè¯ HDFS è¿æ¥ï¼š`hdfs dfsadmin -report`

### JDBC æµ‹è¯•å¤±è´¥

**æ’æŸ¥**ï¼š
- ç¡®è®¤ MySQL è¿è¡Œæ­£å¸¸
- éªŒè¯æ•°æ®åº“è¿æ¥ï¼š`mysql -u root -p$DB_PASS`
- æ£€æŸ¥ MySQL æ—¥å¿—

## 6. å‚è€ƒèµ„æ–™

*   **HugeGraph GitHub ä»“åº“**ï¼š[https://github.com/apache/hugegraph](https://github.com/apache/hugegraph)
*   **HugeGraph å·¥å…·é“¾ GitHub ä»“åº“**ï¼š[https://github.com/apache/hugegraph-toolchain](https://github.com/apache/hugegraph-toolchain)
*   **HugeGraph Server å®˜æ–¹æ–‡æ¡£**ï¼š[https://hugegraph.apache.org/cn/docs/quickstart/hugegraph/hugegraph-server/](https://hugegraph.apache.org/cn/docs/quickstart/hugegraph/hugegraph-server/)
*   **CI è„šæœ¬è·¯å¾„**ï¼š`.github/workflows/*-ci.yml`ï¼ˆHugeGraph å·¥å…·é“¾é¡¹ç›®ä¸­çš„ CI é…ç½®æ–‡ä»¶ï¼Œå¯ä½œä¸ºå‚è€ƒï¼‰
*   **ä¾èµ–æœåŠ¡å®‰è£…è„šæœ¬**ï¼š`hugegraph-*/assembly/travis/`ï¼ˆHugeGraph å·¥å…·é“¾é¡¹ç›®ä¸­ç”¨äº CI å’Œæœ¬åœ°æµ‹è¯•çš„å®‰è£…è„šæœ¬ï¼Œå¯ç›´æ¥ä½¿ç”¨æˆ–ä½œä¸ºå‚è€ƒï¼‰
